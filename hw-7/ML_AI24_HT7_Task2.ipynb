{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Murcha1990/ML_AI24/blob/main/Hometasks/Base/ML_AI24_HT7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7Vud7oB5y9q"
   },
   "source": [
    "# **Домашнее задание 7: Fraud Detection Competition**\n",
    "\n",
    "Добро пожаловать на финальное домашнее задание курса! Домашнее задание направлено на систематизацию всех знаний, полученных в процессе учебы.\n",
    "\n",
    "В нём Вы потренируетесь применять навыки построения пайплайнов машинного обучения, приобретенные в курсе от точки разведочного анализа данных до построения и валидации моделей машинного обучения.\n",
    "\n",
    "## **Задача**\n",
    "**Вы будете решать задачу определения фрода:**\n",
    "\n",
    "https://www.kaggle.com/competitions/fraud-detection-24\n",
    "\n",
    "**Вам нужно будет:**\n",
    "- в jupyter notebook провести исследование данных;\n",
    "- в нём же построить модели и оценить их качество;\n",
    "- отправить посылку на Kaggle.\n",
    "\n",
    "Более подробное описание шагов - в ноутбуке ниже.\n",
    "\n",
    "## **Оценивание и баллы**\n",
    "- В EDA и во всей работе будут оцениваться полнота и **выводы**;\n",
    "- При обучении моделей старайтесь обоснованно подходить к их выбору, избегая простого перебора;\n",
    "\n",
    "**Максимальный балл** - 10 (+ бонусы за Kaggle, см. ниже).\n",
    "\n",
    "\n",
    "Мягкий дедлайн (окончание соревнования на Kaggle): **15 марта 23:59**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:20:29.383466Z",
     "iopub.status.busy": "2025-03-16T11:20:29.382862Z",
     "iopub.status.idle": "2025-03-16T11:20:32.897208Z",
     "shell.execute_reply": "2025-03-16T11:20:32.896344Z",
     "shell.execute_reply.started": "2025-03-16T11:20:29.383422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install catboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IdCmv4IoqxHJ"
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'data'\n",
    "\n",
    "train_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'train_transaction.csv'))\n",
    "train_identity = pd.read_csv(os.path.join(INPUT_DIR, 'train_identity.csv'))\n",
    "test_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'test_transaction.csv'))\n",
    "test_identity = pd.read_csv(os.path.join(INPUT_DIR, 'test_identity.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\n",
    "\n",
    "df_train = train_transaction.merge(train_identity, how='left', on='TransactionID')\n",
    "df_test = test_transaction.merge(test_identity, how='left', on='TransactionID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES0ZdLnfvPm-"
   },
   "source": [
    "### **Примечания:**\n",
    "\n",
    "**1. Оценка качества и Submission File**\n",
    "- Ответом является число от 0 до 1, метрикой качества - AUC-ROC.\n",
    "- Структура Submission File:\n",
    " - для каждого значения *TransactionID* в тестовых данных вы должны предсказать **вероятность** для столбца *isFraud*.\n",
    " - в файле у вас должно быть две колонки: `TransactionID` и`isFraud`  **для каждой транзакции в датасете**.\n",
    "\n",
    "**2. Объем данных**\n",
    "\n",
    "Поскольку набор данных объемный, могут быть проблемы с переполнением памяти в Collab. Для решения проблемы можете использовать функцию из [этого ноутбука](https://colab.research.google.com/drive/18u75eyFGEoyeWJ_MbsLkcPa6gv2tNI8G#scrollTo=V2L1Nl5CTMMl), разобравшись, что она делает с данными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWNI5i4S7VzN"
   },
   "source": [
    "# **Задание 2 (3 балла)**\n",
    "\n",
    "Обучите несколько ML-моделей для решения поставленной задачи.\n",
    "Оцените их качество двумя способами:\n",
    "\n",
    "1) на кросс-валидации\n",
    "\n",
    "2) на лидерборде\n",
    "\n",
    "Подберите число фолдов на кросс-валидации так, чтобы метрики, которые вы видите, были максимально близки на кросс-валидации и на лидерборде.\n",
    "\n",
    "По результатам экспериментов постройте таблицу:\n",
    "* в каждой строке таблицы - результаты одной модели\n",
    "* по столбцам: качество на кросс-валидации, качество на лидерборде, модель с гиперпараметрами\n",
    "Полученную таблицу вставьте картинкой прямо в ноутбук после ячеек с кодом. Сделайте текстовые выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "В предыдущей части было подготовлено 2 дополнительных пары датасетов - с отобранными признаками и с заполненными пропусками.\n",
    "Итого имеем 3 набора данных\n",
    "\n",
    "1. оригинальный с минимальной обработкой\n",
    "2. с отобранными признаками (с пропусками)\n",
    "3. с отобранными признаками и заполненными пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:24:03.498815Z",
     "iopub.status.busy": "2025-03-16T11:24:03.497842Z",
     "iopub.status.idle": "2025-03-16T11:24:04.225806Z",
     "shell.execute_reply": "2025-03-16T11:24:04.225004Z",
     "shell.execute_reply.started": "2025-03-16T11:24:03.498767Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вспомогательная функция для экономии памяти**  \n",
    "Взята из ноутбука, который приводили в пример. \n",
    "Моя реализация выше отличается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:24:05.436741Z",
     "iopub.status.busy": "2025-03-16T11:24:05.435691Z",
     "iopub.status.idle": "2025-03-16T11:24:05.453580Z",
     "shell.execute_reply": "2025-03-16T11:24:05.452809Z",
     "shell.execute_reply.started": "2025-03-16T11:24:05.436699Z"
    }
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    NAlist = [] # Keeps track of columns that have missing values filled in.\n",
    "    for col in tqdm(df.columns):\n",
    "        if df[col].dtype != object:  # Exclude strings\n",
    "\n",
    "            # make variables for Int, max and min\n",
    "            IsInt = False\n",
    "            col_max_value = df[col].max()\n",
    "            col_min_value = df[col].min()\n",
    "\n",
    "            # Integer does not support NA, therefore, NA needs to be filled\n",
    "            if not np.isfinite(df[col]).all():\n",
    "                NAlist.append(col)\n",
    "                df[col] = df[col].fillna(col_min_value - 1)\n",
    "                col_min_value -= 1\n",
    "\n",
    "            # test if column can be converted to an integer\n",
    "            col_as_int = df[col].fillna(0).astype(np.int64)\n",
    "            diff = (df[col] - col_as_int)\n",
    "            diff = diff.sum()\n",
    "            if np.abs(diff) < 0.01:\n",
    "                IsInt = True\n",
    "\n",
    "            # Make Integer/unsigned Integer datatypes\n",
    "            if IsInt:\n",
    "                try:\n",
    "                    if col_min_value >= 0:\n",
    "                        if col_max_value < 255:\n",
    "                            df[col] = df[col].astype(np.uint8)\n",
    "                        elif col_max_value < 65535:\n",
    "                            df[col] = df[col].astype(np.uint16)\n",
    "                        elif col_max_value < 4294967295:\n",
    "                            df[col] = df[col].astype(np.uint32)\n",
    "                        else:\n",
    "                            df[col] = df[col].astype(np.uint64)\n",
    "                    else:\n",
    "                        if col_min_value > np.iinfo(np.int8).min and col_max_value < np.iinfo(np.int8).max:\n",
    "                            df[col] = df[col].astype(np.int8)\n",
    "                        elif col_min_value > np.iinfo(np.int16).min and col_max_value < np.iinfo(np.int16).max:\n",
    "                            df[col] = df[col].astype(np.int16)\n",
    "                        elif col_min_value > np.iinfo(np.int32).min and col_max_value < np.iinfo(np.int32).max:\n",
    "                            df[col] = df[col].astype(np.int32)\n",
    "                        elif col_min_value > np.iinfo(np.int64).min and col_max_value < np.iinfo(np.int64).max:\n",
    "                            df[col] = df[col].astype(np.int64)\n",
    "                except Exception as e:\n",
    "                    print(f'Ошибка конвертации {col}: {e}')\n",
    "\n",
    "            # Make float datatypes 32 bit\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    return df, NAlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исходные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:24:06.986831Z",
     "iopub.status.busy": "2025-03-16T11:24:06.985838Z",
     "iopub.status.idle": "2025-03-16T11:25:52.297435Z",
     "shell.execute_reply": "2025-03-16T11:25:52.296624Z",
     "shell.execute_reply.started": "2025-03-16T11:24:06.986792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 434/434 [00:02<00:00, 184.98it/s]\n",
      "100%|██████████| 433/433 [00:00<00:00, 596.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417559 entries, 0 to 417558\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: float32(80), int16(30), int8(202), object(31), uint16(22), uint32(3), uint8(66)\n",
      "memory usage: 379.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172981 entries, 0 to 172980\n",
      "Columns: 433 entries, TransactionID to DeviceInfo\n",
      "dtypes: float32(78), int16(40), int8(229), object(31), uint16(24), uint32(3), uint8(28)\n",
      "memory usage: 157.9+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DIR = 'data'\n",
    "\n",
    "train_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'train_transaction.csv'))\n",
    "train_identity = pd.read_csv(os.path.join(INPUT_DIR, 'train_identity.csv'))\n",
    "test_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'test_transaction.csv'))\n",
    "test_identity = pd.read_csv(os.path.join(INPUT_DIR, 'test_identity.csv'))\n",
    "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\n",
    "\n",
    "df_train = train_transaction.merge(train_identity, how='left', on='TransactionID')\n",
    "del train_transaction, train_identity\n",
    "df_train, df_train_NAlist = reduce_mem_usage(df_train)\n",
    "\n",
    "df_test = test_transaction.merge(test_identity, how='left', on='TransactionID')\n",
    "del test_transaction, test_identity\n",
    "df_test, df_test_NAlist = reduce_mem_usage(df_test)\n",
    "\n",
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть пропуски"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:25:52.308499Z",
     "iopub.status.busy": "2025-03-16T11:25:52.307756Z",
     "iopub.status.idle": "2025-03-16T11:25:54.545250Z",
     "shell.execute_reply": "2025-03-16T11:25:54.544446Z",
     "shell.execute_reply.started": "2025-03-16T11:25:52.308453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in train: 4.47002%\n",
      "Missing data in test: 4.33051%\n"
     ]
    }
   ],
   "source": [
    "print('Missing data in train: {:.5f}%'.format(df_train.isnull().sum().sum() / (df_train.shape[0] * df_train.shape[1]) * 100))\n",
    "print('Missing data in test: {:.5f}%'.format(df_test.isnull().sum().sum() / (df_test.shape[0] * df_test.shape[1]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заполним пропуски в столбцах, где значения выражаются числами - `-1`, а где строками - `'unseen_category'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:25:54.547730Z",
     "iopub.status.busy": "2025-03-16T11:25:54.546834Z",
     "iopub.status.idle": "2025-03-16T11:25:58.170488Z",
     "shell.execute_reply": "2025-03-16T11:25:58.169679Z",
     "shell.execute_reply.started": "2025-03-16T11:25:54.547693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing data in train: 0.00000%\n",
      "Missing data in test: 0.00000%\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns.drop('isFraud'):\n",
    "    if df_train[col].dtype == 'O':\n",
    "        df_train[col] = df_train[col].fillna('unseen_category')\n",
    "        df_test[col] = df_test[col].fillna('unseen_category')\n",
    "    else:\n",
    "        df_train[col] = df_train[col].fillna(-1)\n",
    "        df_test[col] = df_test[col].fillna(-1)\n",
    "\n",
    "print('Missing data in train: {:.5f}%'.format(df_train.isnull().sum().sum() / (df_train.shape[0] * df_train.shape[1]) * 100))\n",
    "print('Missing data in test: {:.5f}%'.format(df_test.isnull().sum().sum() / (df_test.shape[0] * df_test.shape[1]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закодируем категориальные признаки с помощью [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) и сконвертируем их в [`category`](https://pandas.pydata.org/pandas-docs/version/0.23.4/categorical.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:25:58.172176Z",
     "iopub.status.busy": "2025-03-16T11:25:58.171501Z",
     "iopub.status.idle": "2025-03-16T11:26:14.580793Z",
     "shell.execute_reply": "2025-03-16T11:26:14.580075Z",
     "shell.execute_reply.started": "2025-03-16T11:25:58.172149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 433/433 [00:10<00:00, 39.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417559 entries, 0 to 417558\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: category(31), float32(80), int16(30), int8(202), uint16(22), uint32(3), uint8(66)\n",
      "memory usage: 293.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172981 entries, 0 to 172980\n",
      "Columns: 433 entries, TransactionID to DeviceInfo\n",
      "dtypes: category(31), float32(78), int16(40), int8(229), uint16(24), uint32(3), uint8(28)\n",
      "memory usage: 122.5 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in tqdm(df_train.columns.drop('isFraud')):\n",
    "    if df_train[col].dtype == 'O':\n",
    "        le = LabelEncoder()\n",
    "        le.fit(list(df_train[col]) + list(df_test[col]))\n",
    "        df_train[col] = le.transform(df_train[col])\n",
    "        df_test[col] = le.transform(df_test[col])\n",
    "\n",
    "        df_train[col] = df_train[col].astype('category')\n",
    "        df_test[col] = df_test[col].astype('category')\n",
    "\n",
    "df_train.info(), df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные с отобранными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:26:14.582751Z",
     "iopub.status.busy": "2025-03-16T11:26:14.581579Z",
     "iopub.status.idle": "2025-03-16T11:26:34.512340Z",
     "shell.execute_reply": "2025-03-16T11:26:34.511574Z",
     "shell.execute_reply.started": "2025-03-16T11:26:14.582714Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./data/X_train.csv')\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "\n",
    "X_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Данные с заполненными пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:26:34.514051Z",
     "iopub.status.busy": "2025-03-16T11:26:34.513286Z",
     "iopub.status.idle": "2025-03-16T11:27:37.744952Z",
     "shell.execute_reply": "2025-03-16T11:27:37.744125Z",
     "shell.execute_reply.started": "2025-03-16T11:26:34.514014Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_processed = pd.read_csv('./data/X_train_processed.csv')\n",
    "X_test_processed = pd.read_csv('./data/X_test_processed.csv')\n",
    "\n",
    "X_train_processed.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
    "X_test_processed.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Целевая переменная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:37.747481Z",
     "iopub.status.busy": "2025-03-16T11:27:37.746817Z",
     "iopub.status.idle": "2025-03-16T11:27:37.834285Z",
     "shell.execute_reply": "2025-03-16T11:27:37.833458Z",
     "shell.execute_reply.started": "2025-03-16T11:27:37.747445Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train=pd.read_csv('./data/y_train.csv')\n",
    "y_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выравнивание типов данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:37.836033Z",
     "iopub.status.busy": "2025-03-16T11:27:37.835257Z",
     "iopub.status.idle": "2025-03-16T11:27:45.406471Z",
     "shell.execute_reply": "2025-03-16T11:27:45.405622Z",
     "shell.execute_reply.started": "2025-03-16T11:27:37.836004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417559 entries, 0 to 417558\n",
      "Columns: 334 entries, TransactionAmt to DeviceInfo\n",
      "dtypes: category(31), float64(257), int64(46)\n",
      "memory usage: 978.5 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 417559 entries, 0 to 417558\n",
      "Columns: 498 entries, TransactionAmt to M3_missing\n",
      "dtypes: category(29), float64(128), int64(341)\n",
      "memory usage: 1.5 GB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172981 entries, 0 to 172980\n",
      "Columns: 334 entries, TransactionAmt to DeviceInfo\n",
      "dtypes: category(31), float64(271), int64(32)\n",
      "memory usage: 405.4 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172981 entries, 0 to 172980\n",
      "Columns: 498 entries, TransactionAmt to M3_missing\n",
      "dtypes: category(29), float64(128), int64(341)\n",
      "memory usage: 624.1 MB\n"
     ]
    }
   ],
   "source": [
    "# выравнивание типов данных\n",
    "\n",
    "X_train_cat = X_train.copy()\n",
    "for col in X_train_cat.columns:\n",
    "    if X_train_cat[col].dtype == 'O':\n",
    "        X_train_cat[col] = X_train_cat[col].fillna('unseen_category')\n",
    "        X_train_cat[col] = X_train_cat[col].astype('category')\n",
    "X_train_cat.info()\n",
    "\n",
    "X_train_processed_cat = X_train_processed.copy()\n",
    "for col in X_train_processed.columns:\n",
    "    if X_train_processed_cat[col].dtype == 'O':\n",
    "        X_train_processed_cat[col] = X_train_processed_cat[col].fillna('unseen_category')\n",
    "        X_train_processed_cat[col] = X_train_processed_cat[col].astype('category')\n",
    "X_train_processed_cat.info()\n",
    "\n",
    "X_test_cat = X_test.copy()\n",
    "for col in X_test_cat.columns:\n",
    "    if X_test_cat[col].dtype == 'O':\n",
    "        X_test_cat[col] = X_test_cat[col].fillna('unseen_category')\n",
    "        X_test_cat[col] = X_test_cat[col].astype('category')\n",
    "X_test_cat.info()\n",
    "\n",
    "X_test_processed_cat = X_test_processed.copy()\n",
    "for col in X_train_processed.columns:\n",
    "    if X_test_processed_cat[col].dtype == 'O':\n",
    "        X_test_processed_cat[col] = X_test_processed_cat[col].fillna('unseen_category')\n",
    "        X_test_processed_cat[col] = X_test_processed_cat[col].astype('category')\n",
    "X_test_processed_cat.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка кросс-валидации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я уже провел календарный анализ и показал, что признак `TransactionDT` задан в секундах, а обучающая выборка - это данные за 4 месяца с `07.12.2018` до `06.04.2019`.\n",
    "\n",
    "Тогда логично в качестве фолдов для кроссвалидации взять последовательные подвыборки, соответствующие одному месяцу. Это позволит сохранить распределение признаков внутри фолдов.\n",
    "\n",
    "Зададим фолды при помощи индексов, тогда их можно будет применять ко всем трем наборам данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:45.408492Z",
     "iopub.status.busy": "2025-03-16T11:27:45.407516Z",
     "iopub.status.idle": "2025-03-16T11:27:45.909343Z",
     "shell.execute_reply": "2025-03-16T11:27:45.908566Z",
     "shell.execute_reply.started": "2025-03-16T11:27:45.408453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set 0 length: 134339\n",
      "Validation set 1 length: 89399\n",
      "Validation set 2 length: 92189\n",
      "Validation set 3 length: 101632\n"
     ]
    }
   ],
   "source": [
    "month_length = 3600 * 24 * 30\n",
    "\n",
    "fold0_idx = df_train[df_train['TransactionDT'] < df_train['TransactionDT'].min() + month_length].index\n",
    "fold1_idx = df_train[(df_train['TransactionDT'].min() + month_length <= df_train['TransactionDT']) & (df_train['TransactionDT'] < df_train['TransactionDT'].min() + 2 * month_length)].index\n",
    "fold2_idx = df_train[(df_train['TransactionDT'].min() + 2 * month_length <= df_train['TransactionDT']) & (df_train['TransactionDT'] < df_train['TransactionDT'].min() + 3 * month_length)].index\n",
    "fold3_idx = df_train[df_train['TransactionDT'].min() + 3 * month_length <= df_train['TransactionDT']].index\n",
    "folds_idx = [fold0_idx, fold1_idx, fold2_idx, fold3_idx]\n",
    "\n",
    "print('Validation set 0 length:', len(fold0_idx))\n",
    "print('Validation set 1 length:', len(fold1_idx))\n",
    "print('Validation set 2 length:', len(fold2_idx))\n",
    "print('Validation set 3 length:', len(fold3_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данных есть признак-идентификатор объекта - `'TransactionID'`. Заметим, что его значения в обучающей и тестовых выборках не пересекаются:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:45.911008Z",
     "iopub.status.busy": "2025-03-16T11:27:45.910185Z",
     "iopub.status.idle": "2025-03-16T11:27:45.979027Z",
     "shell.execute_reply": "2025-03-16T11:27:45.978286Z",
     "shell.execute_reply.started": "2025-03-16T11:27:45.910967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train['TransactionID']).intersection(set(df_test['TransactionID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также не пересекаются значения признака, отвечающего за момент времени - `'TransactionDT'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:45.980485Z",
     "iopub.status.busy": "2025-03-16T11:27:45.979977Z",
     "iopub.status.idle": "2025-03-16T11:27:46.084152Z",
     "shell.execute_reply": "2025-03-16T11:27:46.083356Z",
     "shell.execute_reply.started": "2025-03-16T11:27:45.980450Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train['TransactionDT']).intersection(set(df_test['TransactionDT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому удалим эти признаки, чтобы модель их не учитывала.  \n",
    "И удалим `isFraud`  из `df_train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:46.085794Z",
     "iopub.status.busy": "2025-03-16T11:27:46.085087Z",
     "iopub.status.idle": "2025-03-16T11:27:46.364152Z",
     "shell.execute_reply": "2025-03-16T11:27:46.363362Z",
     "shell.execute_reply.started": "2025-03-16T11:27:46.085760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((417559, 431), (172981, 431))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.drop(['TransactionID', 'TransactionDT', 'isFraud'], axis=1, inplace=True)\n",
    "df_test.drop(['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:27:59.614883Z",
     "iopub.status.busy": "2025-03-16T11:27:59.613891Z",
     "iopub.status.idle": "2025-03-16T11:27:59.645550Z",
     "shell.execute_reply": "2025-03-16T11:27:59.644774Z",
     "shell.execute_reply.started": "2025-03-16T11:27:59.614839Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_predict(wrapper_class, params, df_train_num, df_train_cat_encoded, df_train_cat_processed,\n",
    "                     df_test_num, df_test_cat_encoded, df_test_cat_processed,\n",
    "                     y_train, folds_idx, sample_submission,\n",
    "                     save_data=True, save_models=True, submit_to_kaggle=True):\n",
    "    \"\"\"\n",
    "    Обучает три модели на разных наборах признаков и делает предсказания\n",
    "    \n",
    "    Args:\n",
    "        wrapper_class: Класс-обертка для модели (XGBoostWrapper, LightGBMWrapper и т.д.)\n",
    "        params: Параметры модели\n",
    "        df_train_num: Датафрейм с числовыми признаками для обучения\n",
    "        df_train_cat_encoded: Датафрейм с закодированными категориальными признаками для обучения\n",
    "        df_train_cat_processed: Датафрейм с обработанными категориальными признаками для обучения\n",
    "        df_test_num: Тестовый датафрейм с числовыми признаками\n",
    "        df_test_cat_encoded: Тестовый датафрейм с закодированными категориальными признаками\n",
    "        df_test_cat_processed: Тестовый датафрейм с обработанными категориальными признаками\n",
    "        y_train: Целевая переменная\n",
    "        folds_idx: Индексы фолдов для кросс-валидации\n",
    "        sample_submission: Датафрейм с примером сабмита\n",
    "        save_data: Сохранять ли предсказания в файлы\n",
    "        save_models: Сохранять ли обученные модели\n",
    "        submit_to_kaggle: Отправлять ли результаты на Kaggle\n",
    "    \"\"\"\n",
    "    \n",
    "    print('\\nОбучаем модель 1 (числовые + закодированные категориальные признаки)...')\n",
    "    model1 = wrapper_class(params=params)\n",
    "    score1 = model1.fit(df_train_num, y_train, folds_idx)\n",
    "    print(f'CV AUC-ROC: {score1:.5f}')\n",
    "\n",
    "    print('\\nОбучаем модель 2 (числовые + закодированные категориальные признаки)...')\n",
    "    model2 = wrapper_class(params=params)\n",
    "    score2 = model2.fit(df_train_cat_encoded, y_train, folds_idx)\n",
    "    print(f'CV AUC-ROC: {score2:.5f}')\n",
    "\n",
    "    print('\\nОбучаем модель 3 (числовые + обработанные категориальные признаки)...')\n",
    "    model3 = wrapper_class(params=params)\n",
    "    score3 = model3.fit(df_train_cat_processed, y_train, folds_idx)\n",
    "    print(f'CV AUC-ROC: {score3:.5f}')\n",
    "\n",
    "    # Делаем предсказания\n",
    "    print('\\nДелаем предсказания...')\n",
    "    y_pred1 = model1.predict(df_test_num)\n",
    "    y_pred2 = model2.predict(df_test_cat_encoded)\n",
    "    y_pred3 = model3.predict(df_test_cat_processed)\n",
    "    y_pred4 = (y_pred1 + y_pred2 + y_pred3) / 3\n",
    "\n",
    "    print(f'Модель 1 (числовые признаки): {y_pred1.shape}')\n",
    "    print(f'Модель 2 (закодированные категориальные признаки): {y_pred2.shape}')\n",
    "    print(f'Модель 3 (обработанные категориальные признаки): {y_pred3.shape}')\n",
    "    print(f'Модель 4 (усреднение 1, 2 и 3): {y_pred4.shape}')\n",
    "\n",
    "    if save_data:\n",
    "        # Создаем сабмиты\n",
    "        sub1 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred1})\n",
    "        sub2 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred2})\n",
    "        sub3 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred3})\n",
    "        sub4 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred4})\n",
    "\n",
    "        # Сохраняем сабмиты\n",
    "        sub1.to_csv('data/submission_model1.csv', index=False)\n",
    "        sub2.to_csv('data/submission_model2.csv', index=False)\n",
    "        sub3.to_csv('data/submission_model3.csv', index=False)\n",
    "        sub4.to_csv('data/submission_model4.csv', index=False)\n",
    "\n",
    "    if submit_to_kaggle:\n",
    "        # Отправляем результаты\n",
    "        !kaggle competitions submit -c fraud-detection-24 -f data/submission_model1.csv -m \"Task2: model1\"\n",
    "        !kaggle competitions submit -c fraud-detection-24 -f data/submission_model2.csv -m \"Task2: model2\"\n",
    "        !kaggle competitions submit -c fraud-detection-24 -f data/submission_model3.csv -m \"Task2: model3\"\n",
    "        !kaggle competitions submit -c fraud-detection-24 -f data/submission_model4.csv -m \"Task2: model4\"\n",
    "\n",
    "    if save_models:\n",
    "        # Сохраняем модели\n",
    "        joblib.dump(model1, 'models/model1.joblib')\n",
    "        joblib.dump(model2, 'models/model2.joblib')\n",
    "        joblib.dump(model3, 'models/model3.joblib')\n",
    "        \n",
    "    return model1, model2, model3, (y_pred1, y_pred2, y_pred3, y_pred4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:32:36.037089Z",
     "iopub.status.busy": "2025-03-16T11:32:36.035970Z",
     "iopub.status.idle": "2025-03-16T11:32:36.072803Z",
     "shell.execute_reply": "2025-03-16T11:32:36.072074Z",
     "shell.execute_reply.started": "2025-03-16T11:32:36.037047Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "\n",
    "class LightGBMWrapper(BaseEstimator):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.models = []\n",
    "        self.scores = []\n",
    "        self.models = []\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, folds_idx: list[np.ndarray]):\n",
    "        for i in range(len(folds_idx)):\n",
    "            _X_train = X.drop(folds_idx[i], axis=0)\n",
    "            _y_train = y.drop(folds_idx[i], axis=0)\n",
    "            _X_val = X.iloc[folds_idx[i]]\n",
    "            _y_val = y.iloc[folds_idx[i]]\n",
    "            \n",
    "            lgb_train = lgb.Dataset(_X_train, _y_train)\n",
    "            lgb_eval = lgb.Dataset(_X_val, _y_val, reference=lgb_train)\n",
    "            \n",
    "            _model = lgb.train(self.params, lgb_train, valid_sets=lgb_eval)\n",
    "            self.models.append(_model)\n",
    "            \n",
    "            _y_pred = _model.predict(_X_val)\n",
    "            score_fold = roc_auc_score(_y_val, _y_pred)\n",
    "            self.scores.append(score_fold)\n",
    "            \n",
    "        return np.mean(self.scores)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self.models:\n",
    "            raise ValueError(\"Модель не обучена. Сначала выполните fit()\")\n",
    "            \n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            predictions.append(model.predict(X))\n",
    "        return np.mean(predictions, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:38:40.967096Z",
     "iopub.status.busy": "2025-03-16T11:38:40.966138Z",
     "iopub.status.idle": "2025-03-16T11:38:40.977615Z",
     "shell.execute_reply": "2025-03-16T11:38:40.976817Z",
     "shell.execute_reply.started": "2025-03-16T11:38:40.967063Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 2000,\n",
    "    'seed': 42,\n",
    "    'early_stopping_rounds': 200,\n",
    "    # 'device': \"gpu\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:38:41.987805Z",
     "iopub.status.busy": "2025-03-16T11:38:41.986903Z",
     "iopub.status.idle": "2025-03-16T11:46:14.089698Z",
     "shell.execute_reply": "2025-03-16T11:46:14.088691Z",
     "shell.execute_reply.started": "2025-03-16T11:38:41.987778Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучаем модель 1 (числовые + закодированные категориальные признаки)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.158217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 31545\n",
      "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 429\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
      "[LightGBM] [Info] Start training from score -3.178863\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[575]\tvalid_0's auc: 0.900345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.206276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34468\n",
      "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 429\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
      "[LightGBM] [Info] Start training from score -3.348051\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[591]\tvalid_0's auc: 0.9241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34365\n",
      "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 429\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
      "[LightGBM] [Info] Start training from score -3.352958\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[497]\tvalid_0's auc: 0.9239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.197913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34516\n",
      "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 429\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
      "[LightGBM] [Info] Start training from score -3.350619\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[507]\tvalid_0's auc: 0.905748\n",
      "CV AUC-ROC: 0.91352\n",
      "\n",
      "Обучаем модель 2 (числовые + закодированные категориальные признаки)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.113447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 25969\n",
      "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 332\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
      "[LightGBM] [Info] Start training from score -3.178863\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[773]\tvalid_0's auc: 0.904735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.129329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28079\n",
      "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 332\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
      "[LightGBM] [Info] Start training from score -3.348051\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[540]\tvalid_0's auc: 0.922969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.153709 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 27996\n",
      "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 332\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
      "[LightGBM] [Info] Start training from score -3.352958\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's auc: 0.922556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 28125\n",
      "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 332\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
      "[LightGBM] [Info] Start training from score -3.350619\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's auc: 0.90299\n",
      "CV AUC-ROC: 0.91331\n",
      "\n",
      "Обучаем модель 3 (числовые + обработанные категориальные признаки)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 34427\n",
      "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 494\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
      "[LightGBM] [Info] Start training from score -3.178863\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[547]\tvalid_0's auc: 0.901046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.233838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36660\n",
      "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 495\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
      "[LightGBM] [Info] Start training from score -3.348051\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\tvalid_0's auc: 0.925485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.211044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36500\n",
      "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 494\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
      "[LightGBM] [Info] Start training from score -3.352958\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[466]\tvalid_0's auc: 0.923908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.194183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 36729\n",
      "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 495\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
      "[LightGBM] [Info] Start training from score -3.350619\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.903265\n",
      "CV AUC-ROC: 0.91343\n",
      "\n",
      "Делаем предсказания...\n",
      "Модель 1 (числовые признаки): (172981,)\n",
      "Модель 2 (закодированные категориальные признаки): (172981,)\n",
      "Модель 3 (обработанные категориальные признаки): (172981,)\n",
      "Модель 4 (усреднение 1, 2 и 3): (172981,)\n"
     ]
    }
   ],
   "source": [
    "lgb1, lgb2, lgb3, (y_pred1, y_pred2, y_pred3, y_pred4) = train_and_predict(LightGBMWrapper, params, df_train, X_train_cat, X_train_processed_cat,\n",
    "                  df_test, X_test_cat, X_test_processed_cat,\n",
    "                  y_train, folds_idx, sample_submission, save_data=False, save_models=False, submit_to_kaggle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb1 = LightGBMWrapper(params=params)\n",
    "# score1 = lgb1.fit(df_train, y_train, folds_idx)\n",
    "# print('CV AUC-ROC: {:.5f}'.format(np.mean(score1)))\n",
    "\n",
    "# lgb2 = LightGBMWrapper(params=params)\n",
    "# score2 = lgb2.fit(X_train_cat, y_train, folds_idx)\n",
    "# print('CV AUC-ROC: {:.5f}'.format(np.mean(score2)))\n",
    "\n",
    "# lgb3 = LightGBMWrapper(params=params)\n",
    "# score3 = lgb3.fit(X_train_processed_cat, y_train, folds_idx)\n",
    "# print('CV AUC-ROC: {:.5f}'.format(np.mean(score3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:36:04.646480Z",
     "iopub.status.busy": "2025-03-16T11:36:04.645582Z",
     "iopub.status.idle": "2025-03-16T11:36:12.878445Z",
     "shell.execute_reply": "2025-03-16T11:36:12.877679Z",
     "shell.execute_reply.started": "2025-03-16T11:36:04.646442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказания сделаны для всех трех моделей:\n",
      "Модель 1 (базовая): (172981,)\n",
      "Модель 2 (категориальные признаки): (172981,)\n",
      "Модель 3 (обработанные категориальные признаки): (172981,)\n",
      "Модель 4 (усреднение 1, 2 и 3): (172981,)\n"
     ]
    }
   ],
   "source": [
    "# # Предсказания для всех трех моделей\n",
    "# y_pred1 = lgb1.predict(df_test)\n",
    "# y_pred2 = lgb2.predict(X_test_cat)\n",
    "# y_pred3 = lgb3.predict(X_test_processed_cat)\n",
    "# # Усредняем предсказания всех трех моделей\n",
    "# y_pred4 = (y_pred1 + y_pred2 + y_pred3) / 3\n",
    "\n",
    "\n",
    "# print('Предсказания сделаны для всех трех моделей:')\n",
    "# print(f'Модель 1 (базовая): {y_pred1.shape}')\n",
    "# print(f'Модель 2 (категориальные признаки): {y_pred2.shape}') \n",
    "# print(f'Модель 3 (обработанные категориальные признаки): {y_pred3.shape}')\n",
    "# print(f'Модель 4 (усреднение 1, 2 и 3): {y_pred4.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3404559</td>\n",
       "      <td>0.006539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3404560</td>\n",
       "      <td>0.060885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3404561</td>\n",
       "      <td>0.013823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3404562</td>\n",
       "      <td>0.006402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3404563</td>\n",
       "      <td>0.500748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3404559  0.006539\n",
       "1        3404560  0.060885\n",
       "2        3404561  0.013823\n",
       "3        3404562  0.006402\n",
       "4        3404563  0.500748"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred1})\n",
    "sub2 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred2})\n",
    "sub3 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred3})\n",
    "sub4 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred4})\n",
    "\n",
    "sub4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sub1.to_csv(f'data/submission_lgbm1_{timestamp}.csv', index=False) # Score: 0.91599\n",
    "sub2.to_csv(f'data/submission_lgbm2_{timestamp}.csv', index=False) # Score: 0.91674\n",
    "sub3.to_csv(f'data/submission_lgbm3_{timestamp}.csv', index=False) # Score: 0.91699\n",
    "sub4.to_csv(f'data/submission_lgbm4_{timestamp}.csv', index=False) # Score: 0.92049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 4.81M/4.81M [00:01<00:00, 2.94MB/s]\n",
      "100%|██████████████████████████████████████| 4.81M/4.81M [00:01<00:00, 2.98MB/s]\n",
      "100%|██████████████████████████████████████| 4.80M/4.80M [00:01<00:00, 3.11MB/s]\n",
      "100%|██████████████████████████████████████| 4.80M/4.80M [00:01<00:00, 3.11MB/s]\n",
      "Successfully submitted to Fraud Detection Competition"
     ]
    }
   ],
   "source": [
    "# # Отправка файла на соревнование\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm1_{timestamp}.csv -m \"Task2: lgbm1\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm2_{timestamp}.csv -m \"Task2: lgbm2\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm3_{timestamp}.csv -m \"Task2: lgbm3\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm4_{timestamp}.csv -m \"Task2: lgbm4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/model_lgb3.joblib']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Сохраняем все модели.\n",
    "# В LightGBM есть встроенная функция сохранения модели, но у нас самодельная кросс-валидация и 4 модели внутри.\n",
    "# Поэтому сохраняем вручную.\n",
    "import joblib\n",
    "\n",
    "joblib.dump(lgb1, f'models/model_lgb1_{timestamp}.joblib')\n",
    "joblib.dump(lgb2, f'models/model_lgb2_{timestamp}.joblib')\n",
    "joblib.dump(lgb3, f'models/model_lgb3_{timestamp}.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Результаты и выводы\n",
    "\n",
    "**Подход к построению моделей**\n",
    "1. Были обучены 3 базовые модели LightGBM на разных наборах данных:\n",
    "   - `lgb1` - на исходных данных с базовой предобработкой\n",
    "   - `lgb2` - на данных с отобранными признаками\n",
    "   - `lgb3` - на данных с заполненными пропусками и дополнительной обработкой\n",
    "2. Использована кастомная реализация кросс-валидации:\n",
    "   - 4 фолда, разделенные по временным периодам (по месяцам)\n",
    "   - Это позволило сохранить временную структуру данных\n",
    "   - Каждая модель обучалась отдельно на каждом фолде\n",
    "  \n",
    "Параметры всех моделей\n",
    "```python\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'n_jobs': -1,\n",
    "    'n_estimators': 2000,\n",
    "    'seed': 13,\n",
    "    'early_stopping_rounds': 200\n",
    "}\n",
    "```\n",
    "**Результаты**\n",
    "| Модель                              | AUC-ROC |  Kaggle |\n",
    "|-------------------------------------|---------|---------|\n",
    "| `lbg1` (базовая)                    | 0.91476 | 0.91599 |\n",
    "| `lgb2` (с отобранными признаками)   | 0.91271 | 0.91674 |\n",
    "| `lgb3` (с обработанными признаками) | 0.91269 | 0.91699 |\n",
    "| Ансамбль (среднее трёх моделей)     |       - | 0.92049 |\n",
    "\n",
    "AUC-ROC ансамбля не указан, т.к. внутри моделей скрыта кастомная кроссвалидация и эти значения AUC-ROC - это уже усредненные AUC-ROC на фолдах.\n",
    "\n",
    "**Выводы**\n",
    "\n",
    "1. **Стабильность**:  \n",
    "        Все три модели показали близкие результаты как на кросс-валидации (CV), так и на тестовой выборке (Kaggle), что говорит о стабильности подхода.\n",
    "2. **Эффективность ансамблирования**:  \n",
    "        Усреднение предсказаний дало значительное улучшение результата (0.92049), что превосходит каждую индивидуальную модель на 0.4%-0.6%\n",
    "3. **Соответствие CV и лидерборда**:  \n",
    "        Результаты на CV хорошо коррелируют с результатами на Kaggle, что подтверждает корректность выбранной схемы валидации.\n",
    "4. **Влияние предобработки**:  \n",
    "        Интересно что более сложная предобработка данных (модели 2 и 3) не дала существенного преимущества на CV, но показала лучшие результаты на тестовой выборке. \n",
    "\n",
    "> Лучшим решением оказался ансамбль всех трёх моделей, что подчеркивает важность разнообразия подходов к обработке данных и построению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "class CatboostWrapper(BaseEstimator):\n",
    "    def __init__(self, params):\n",
    "        self.params = params\n",
    "        self.models = []\n",
    "        self.scores = []\n",
    "        \n",
    "    def fit(self, X: pd.DataFrame, y: pd.Series, folds_idx: list[np.ndarray]):\n",
    "        cat_features = X.select_dtypes(include=['category']).columns.tolist()\n",
    "        for i in range(len(folds_idx)):\n",
    "            _X_train = X.drop(folds_idx[i], axis=0)\n",
    "            _y_train = y.drop(folds_idx[i], axis=0)\n",
    "            _X_val = X.iloc[folds_idx[i]]\n",
    "            _y_val = y.iloc[folds_idx[i]]\n",
    "            \n",
    "            cb_train = cb.Pool(_X_train, _y_train, cat_features=cat_features)\n",
    "            cb_eval = cb.Pool(_X_val, _y_val, cat_features=cat_features)\n",
    "            \n",
    "            model = cb.CatBoostClassifier(**self.params)\n",
    "            model.fit(cb_train, eval_set=cb_eval)\n",
    "            self.models.append(model)\n",
    "            # model.save_model(fname=f'models/cb_fold_{i}_{timestamp}.cbm', format=\"cbm\")\n",
    "\n",
    "            # _model = lgb.train(self.params, lgb_train, valid_sets=lgb_eval)\n",
    "            # self.models.append(_model)\n",
    "            \n",
    "            _y_pred = model.predict_proba(_X_val)[:, 1]\n",
    "            score_fold = roc_auc_score(_y_val, _y_pred)\n",
    "            self.scores.append(score_fold)\n",
    "            \n",
    "        return np.mean(self.scores)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self.models:\n",
    "            raise ValueError(\"Модель не обучена. Сначала выполните fit()\")\n",
    "            \n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            predictions.append(model.predict(X))\n",
    "        return np.mean(predictions, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'learning_rate': 0.2,\n",
    "    'iterations': 200,\n",
    "    'random_seed': 42,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'verbose': 200,\n",
    "    # 'task_type': \"GPU\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb1 = CatboostWrapper(params=params)\n",
    "score1 = cb1.fit(df_train, y_train, folds_idx)\n",
    "print('CV AUC-ROC: {:.5f}'.format(np.mean(score1)))\n",
    "\n",
    "cb2 = CatboostWrapper(params=params)\n",
    "score2 = cb2.fit(X_train_cat, y_train, folds_idx)\n",
    "print('CV AUC-ROC: {:.5f}'.format(np.mean(score2)))\n",
    "\n",
    "cb3 = CatboostWrapper(params=params)\n",
    "score3 = cb3.fit(X_train_processed_cat, y_train, folds_idx)\n",
    "print('CV AUC-ROC: {:.5f}'.format(np.mean(score3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания для всех трех моделей\n",
    "y_pred1 = cb1.predict(df_test)\n",
    "y_pred2 = cb2.predict(X_test_cat)\n",
    "y_pred3 = cb3.predict(X_test_processed_cat)\n",
    "# Усредняем предсказания всех трех моделей\n",
    "y_pred4 = (y_pred1 + y_pred2 + y_pred3) / 3\n",
    "\n",
    "\n",
    "print('Предсказания сделаны для всех трех моделей:')\n",
    "print(f'Модель 1 (базовая): {y_pred1.shape}')\n",
    "print(f'Модель 2 (категориальные признаки): {y_pred2.shape}') \n",
    "print(f'Модель 3 (обработанные категориальные признаки): {y_pred3.shape}')\n",
    "print(f'Модель 4 (усреднение 1, 2 и 3): {y_pred4.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred1})\n",
    "sub2 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred2})\n",
    "sub3 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred3})\n",
    "sub4 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred4})\n",
    "\n",
    "sub4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1.to_csv('data/submission_cb1.csv', index=False) # Score: (0.91599)\n",
    "sub2.to_csv('data/submission_cb2.csv', index=False) # Score: (0.91674)\n",
    "sub3.to_csv('data/submission_cb3.csv', index=False) # Score: (0.91699)\n",
    "sub4.to_csv('data/submission_cb4.csv', index=False) # Score: (0.92049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 1.98M/1.98M [00:01<00:00, 1.36MB/s]\n",
      "100%|██████████████████████████████████████| 1.98M/1.98M [00:01<00:00, 1.28MB/s]\n",
      "100%|██████████████████████████████████████| 1.98M/1.98M [00:01<00:00, 1.52MB/s]\n",
      "100%|██████████████████████████████████████| 2.01M/2.01M [00:01<00:00, 1.40MB/s]\n",
      "Successfully submitted to Fraud Detection Competition"
     ]
    }
   ],
   "source": [
    "# # Отправка файла на соревнование\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_cb1.csv -m \"Task2: cb1\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_cb2.csv -m \"Task2: cb2\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_cb3.csv -m \"Task2: cb3\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_cb4.csv -m \"Task2: cb4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем все модели.\n",
    "# В LightGBM есть встроенная функция сохранения модели, но у нас самодельная кросс-валидация и 4 модели внутри.\n",
    "# Поэтому сохраняем вручную.\n",
    "import joblib\n",
    "\n",
    "joblib.dump(cb1, 'models/model_cb1.joblib')\n",
    "joblib.dump(cb2, 'models/model_cb2.joblib')\n",
    "joblib.dump(cb3, 'models/model_cb3.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Если запускается в разнобой, то предварительно выполнить ячейки\n",
    "> - Загрузка данных\n",
    "> - Подготовка кросс-валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:07.800336Z",
     "iopub.status.busy": "2025-03-16T11:28:07.799385Z",
     "iopub.status.idle": "2025-03-16T11:28:07.817379Z",
     "shell.execute_reply": "2025-03-16T11:28:07.816591Z",
     "shell.execute_reply.started": "2025-03-16T11:28:07.800300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Реализуем аналогичный подход с XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "class XGBoostWrapper:\n",
    "    def __init__(self, params=None):\n",
    "        self.models = []\n",
    "        self.params = params if params else {\n",
    "            'n_estimators': 1000,\n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 5,\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'objective': 'binary:logistic',\n",
    "            'eval_metric': 'auc',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y, folds_idx):\n",
    "        scores = []\n",
    "        for i, fold_idx in enumerate(folds_idx):\n",
    "            X_train = X.drop(fold_idx, axis=0)\n",
    "            y_train = y.drop(fold_idx, axis=0)\n",
    "            X_valid = X.iloc[fold_idx]\n",
    "            y_valid = y.iloc[fold_idx]\n",
    "             \n",
    "            model = XGBClassifier(**self.params)\n",
    "            # В новых версиях XGBoost early_stopping_rounds передается через fit_params\n",
    "            model.fit(\n",
    "                X_train, y_train,\n",
    "                eval_set=[(X_valid, y_valid)],\n",
    "                verbose=100\n",
    "            )\n",
    "            \n",
    "            self.models.append(model)\n",
    "            score = roc_auc_score(y_valid, model.predict_proba(X_valid)[:, 1])\n",
    "            scores.append(score)\n",
    "            print(f'Fold {i + 1} ROC AUC: {score}')\n",
    "            \n",
    "        print(f'Mean ROC AUC: {np.mean(scores)}')\n",
    "        return np.mean(scores)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict_proba(X)[:, 1]\n",
    "            preds.append(pred)\n",
    "        return np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:10.256640Z",
     "iopub.status.busy": "2025-03-16T11:28:10.255632Z",
     "iopub.status.idle": "2025-03-16T11:28:10.269103Z",
     "shell.execute_reply": "2025-03-16T11:28:10.268367Z",
     "shell.execute_reply.started": "2025-03-16T11:28:10.256597Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 1000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 7,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'early_stopping_rounds': 200,  # Добавляем early_stopping_rounds в параметры модели\n",
    "    'enable_categorical': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-16T11:28:12.789910Z",
     "iopub.status.busy": "2025-03-16T11:28:12.788975Z",
     "iopub.status.idle": "2025-03-16T11:28:13.392240Z",
     "shell.execute_reply": "2025-03-16T11:28:13.390979Z",
     "shell.execute_reply.started": "2025-03-16T11:28:12.789869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучаем модель 1 (числовые + закодированные категориальные признаки)...\n",
      "[0]\tvalidation_0-auc:0.78011\n",
      "[100]\tvalidation_0-auc:0.83986\n",
      "[200]\tvalidation_0-auc:0.85323\n",
      "[300]\tvalidation_0-auc:0.86210\n",
      "[400]\tvalidation_0-auc:0.86971\n",
      "[500]\tvalidation_0-auc:0.87576\n",
      "[600]\tvalidation_0-auc:0.88150\n",
      "[700]\tvalidation_0-auc:0.88588\n",
      "[800]\tvalidation_0-auc:0.88915\n",
      "[900]\tvalidation_0-auc:0.89191\n",
      "[999]\tvalidation_0-auc:0.89456\n",
      "Fold 1 ROC AUC: 0.8945600108926582\n",
      "[0]\tvalidation_0-auc:0.79360\n",
      "[100]\tvalidation_0-auc:0.86195\n",
      "[200]\tvalidation_0-auc:0.87727\n",
      "[300]\tvalidation_0-auc:0.88960\n",
      "[400]\tvalidation_0-auc:0.89632\n",
      "[500]\tvalidation_0-auc:0.90056\n",
      "[600]\tvalidation_0-auc:0.90465\n",
      "[700]\tvalidation_0-auc:0.90848\n",
      "[800]\tvalidation_0-auc:0.91108\n",
      "[900]\tvalidation_0-auc:0.91335\n",
      "[999]\tvalidation_0-auc:0.91554\n",
      "Fold 2 ROC AUC: 0.9155386642071525\n",
      "[0]\tvalidation_0-auc:0.80409\n",
      "[100]\tvalidation_0-auc:0.88325\n",
      "[200]\tvalidation_0-auc:0.89480\n",
      "[300]\tvalidation_0-auc:0.90438\n",
      "[400]\tvalidation_0-auc:0.90914\n",
      "[500]\tvalidation_0-auc:0.91204\n",
      "[600]\tvalidation_0-auc:0.91411\n",
      "[700]\tvalidation_0-auc:0.91595\n",
      "[800]\tvalidation_0-auc:0.91698\n",
      "[900]\tvalidation_0-auc:0.91804\n",
      "[999]\tvalidation_0-auc:0.91900\n",
      "Fold 3 ROC AUC: 0.9189947106585691\n",
      "[0]\tvalidation_0-auc:0.76046\n",
      "[100]\tvalidation_0-auc:0.85976\n",
      "[200]\tvalidation_0-auc:0.87088\n",
      "[300]\tvalidation_0-auc:0.88282\n",
      "[400]\tvalidation_0-auc:0.89131\n",
      "[500]\tvalidation_0-auc:0.89579\n",
      "[600]\tvalidation_0-auc:0.89895\n",
      "[700]\tvalidation_0-auc:0.90122\n",
      "[800]\tvalidation_0-auc:0.90272\n",
      "[900]\tvalidation_0-auc:0.90406\n",
      "[999]\tvalidation_0-auc:0.90520\n",
      "Fold 4 ROC AUC: 0.9051950131754969\n",
      "Mean ROC AUC: 0.9085720997334692\n",
      "CV AUC-ROC: 0.90857\n",
      "\n",
      "Обучаем модель 2 (числовые + закодированные категориальные признаки)...\n",
      "[0]\tvalidation_0-auc:0.76007\n",
      "[100]\tvalidation_0-auc:0.83939\n",
      "[200]\tvalidation_0-auc:0.85412\n",
      "[300]\tvalidation_0-auc:0.86192\n",
      "[400]\tvalidation_0-auc:0.86985\n",
      "[500]\tvalidation_0-auc:0.87629\n",
      "[600]\tvalidation_0-auc:0.88199\n",
      "[700]\tvalidation_0-auc:0.88556\n",
      "[800]\tvalidation_0-auc:0.88848\n",
      "[900]\tvalidation_0-auc:0.89124\n",
      "[999]\tvalidation_0-auc:0.89355\n",
      "Fold 1 ROC AUC: 0.8935530779881327\n",
      "[0]\tvalidation_0-auc:0.79928\n",
      "[100]\tvalidation_0-auc:0.86332\n",
      "[200]\tvalidation_0-auc:0.87817\n",
      "[300]\tvalidation_0-auc:0.89016\n",
      "[400]\tvalidation_0-auc:0.89748\n",
      "[500]\tvalidation_0-auc:0.90169\n",
      "[600]\tvalidation_0-auc:0.90504\n",
      "[700]\tvalidation_0-auc:0.90853\n",
      "[800]\tvalidation_0-auc:0.91151\n",
      "[900]\tvalidation_0-auc:0.91372\n",
      "[999]\tvalidation_0-auc:0.91561\n",
      "Fold 2 ROC AUC: 0.9156095780275388\n",
      "[0]\tvalidation_0-auc:0.80235\n",
      "[100]\tvalidation_0-auc:0.88117\n",
      "[200]\tvalidation_0-auc:0.89369\n",
      "[300]\tvalidation_0-auc:0.90425\n",
      "[400]\tvalidation_0-auc:0.90907\n",
      "[500]\tvalidation_0-auc:0.91184\n",
      "[600]\tvalidation_0-auc:0.91350\n",
      "[700]\tvalidation_0-auc:0.91509\n",
      "[800]\tvalidation_0-auc:0.91598\n",
      "[900]\tvalidation_0-auc:0.91725\n",
      "[999]\tvalidation_0-auc:0.91798\n",
      "Fold 3 ROC AUC: 0.9179779267872388\n",
      "[0]\tvalidation_0-auc:0.75712\n",
      "[100]\tvalidation_0-auc:0.85930\n",
      "[200]\tvalidation_0-auc:0.87222\n",
      "[300]\tvalidation_0-auc:0.88466\n",
      "[400]\tvalidation_0-auc:0.89207\n",
      "[500]\tvalidation_0-auc:0.89697\n",
      "[600]\tvalidation_0-auc:0.89948\n",
      "[700]\tvalidation_0-auc:0.90198\n",
      "[800]\tvalidation_0-auc:0.90355\n",
      "[900]\tvalidation_0-auc:0.90505\n",
      "[999]\tvalidation_0-auc:0.90584\n",
      "Fold 4 ROC AUC: 0.905844403141097\n",
      "Mean ROC AUC: 0.9082462464860018\n",
      "CV AUC-ROC: 0.90825\n",
      "\n",
      "Обучаем модель 3 (числовые + обработанные категориальные признаки)...\n",
      "[0]\tvalidation_0-auc:0.78860\n",
      "[100]\tvalidation_0-auc:0.83973\n",
      "[200]\tvalidation_0-auc:0.85531\n",
      "[300]\tvalidation_0-auc:0.86299\n",
      "[400]\tvalidation_0-auc:0.87034\n",
      "[500]\tvalidation_0-auc:0.87654\n",
      "[600]\tvalidation_0-auc:0.88112\n",
      "[700]\tvalidation_0-auc:0.88506\n",
      "[800]\tvalidation_0-auc:0.88823\n",
      "[900]\tvalidation_0-auc:0.89060\n",
      "[999]\tvalidation_0-auc:0.89333\n",
      "Fold 1 ROC AUC: 0.8933274391916226\n",
      "[0]\tvalidation_0-auc:0.79442\n",
      "[100]\tvalidation_0-auc:0.86238\n",
      "[200]\tvalidation_0-auc:0.88024\n",
      "[300]\tvalidation_0-auc:0.89162\n",
      "[400]\tvalidation_0-auc:0.89913\n",
      "[500]\tvalidation_0-auc:0.90435\n",
      "[600]\tvalidation_0-auc:0.90680\n",
      "[700]\tvalidation_0-auc:0.91008\n",
      "[800]\tvalidation_0-auc:0.91280\n",
      "[900]\tvalidation_0-auc:0.91493\n",
      "[999]\tvalidation_0-auc:0.91661\n",
      "Fold 2 ROC AUC: 0.9166192697165487\n",
      "[0]\tvalidation_0-auc:0.81567\n",
      "[100]\tvalidation_0-auc:0.87920\n",
      "[200]\tvalidation_0-auc:0.89488\n",
      "[300]\tvalidation_0-auc:0.90470\n",
      "[400]\tvalidation_0-auc:0.90925\n",
      "[500]\tvalidation_0-auc:0.91233\n",
      "[600]\tvalidation_0-auc:0.91409\n",
      "[700]\tvalidation_0-auc:0.91566\n",
      "[800]\tvalidation_0-auc:0.91672\n",
      "[900]\tvalidation_0-auc:0.91752\n",
      "[999]\tvalidation_0-auc:0.91830\n",
      "Fold 3 ROC AUC: 0.9182974305834266\n",
      "[0]\tvalidation_0-auc:0.78537\n",
      "[100]\tvalidation_0-auc:0.85836\n",
      "[200]\tvalidation_0-auc:0.87294\n",
      "[300]\tvalidation_0-auc:0.88526\n",
      "[400]\tvalidation_0-auc:0.89276\n",
      "[500]\tvalidation_0-auc:0.89728\n",
      "[600]\tvalidation_0-auc:0.89993\n",
      "[700]\tvalidation_0-auc:0.90227\n",
      "[800]\tvalidation_0-auc:0.90369\n",
      "[900]\tvalidation_0-auc:0.90511\n",
      "[999]\tvalidation_0-auc:0.90602\n",
      "Fold 4 ROC AUC: 0.9060184761539358\n",
      "Mean ROC AUC: 0.9085656539113834\n",
      "CV AUC-ROC: 0.90857\n",
      "\n",
      "Делаем предсказания...\n",
      "Модель 1 (числовые признаки): (172981,)\n",
      "Модель 2 (закодированные категориальные признаки): (172981,)\n",
      "Модель 3 (обработанные категориальные признаки): (172981,)\n",
      "Модель 4 (усреднение 1, 2 и 3): (172981,)\n"
     ]
    }
   ],
   "source": [
    "# Обучаем три модели с разными наборами признаков\n",
    "xgb1, xgb2, xgb3, (y_pred1, y_pred2, y_pred3, y_pred4) = train_and_predict(XGBoostWrapper, params, df_train, X_train_cat, X_train_processed_cat,\n",
    "                  df_test, X_test_cat, X_test_processed_cat,\n",
    "                  y_train, folds_idx, sample_submission, save_data=False, save_models=False, submit_to_kaggle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3404559</td>\n",
       "      <td>0.033731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3404560</td>\n",
       "      <td>0.330279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3404561</td>\n",
       "      <td>0.329900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3404562</td>\n",
       "      <td>0.038083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3404563</td>\n",
       "      <td>0.358853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID   isFraud\n",
       "0        3404559  0.033731\n",
       "1        3404560  0.330279\n",
       "2        3404561  0.329900\n",
       "3        3404562  0.038083\n",
       "4        3404563  0.358853"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub1 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred1})\n",
    "sub2 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred2})\n",
    "sub3 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred3})\n",
    "sub4 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred4})\n",
    "\n",
    "sub4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "sub1.to_csv(f'data/submission_xgb1_{timestamp}.csv', index=False) # Score: 0.91599\n",
    "sub2.to_csv(f'data/submission_xgb2_{timestamp}.csv', index=False) # Score: 0.91674\n",
    "sub3.to_csv(f'data/submission_xgb3_{timestamp}.csv', index=False) # Score: 0.91699\n",
    "sub4.to_csv(f'data/submission_xgb4_{timestamp}.csv', index=False) # Score: 0.92049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 3.21M/3.21M [00:01<00:00, 2.10MB/s]\n",
      "100%|██████████████████████████████████████| 3.22M/3.22M [00:01<00:00, 2.20MB/s]\n",
      "100%|██████████████████████████████████████| 3.27M/3.27M [00:01<00:00, 2.19MB/s]\n",
      "100%|██████████████████████████████████████| 3.23M/3.23M [00:01<00:00, 2.18MB/s]\n",
      "Successfully submitted to Fraud Detection Competition"
     ]
    }
   ],
   "source": [
    "# # Отправка файла на соревнование\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_xgb1_{timestamp}.csv -m \"Task2: xgb1\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_xgb2_{timestamp}.csv -m \"Task2: xgb2\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_xgb3_{timestamp}.csv -m \"Task2: xgb3\"\n",
    "!kaggle competitions submit -c fraud-detection-24 -f data/submission_xgb4_{timestamp}.csv -m \"Task2: xgb4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYedT0TJ79RC"
   },
   "source": [
    "# **Задание 3 (2 балла)**\n",
    "\n",
    "Попробуйте подойти к задаче как к поиску аномалий.\n",
    "\n",
    "1) Поищите аномалии (фрод) различными рассмотренными в курсе методами и сделайте прогноз на тестовых данных.\n",
    "\n",
    "Результатом также будет таблица:\n",
    "* по строкам - методы поиска аномалий\n",
    "* по столбцам - качество вашего решения на leaderboard\n",
    "\n",
    "2) Попробуйте встроить поиск аномалий и их удаление в ML-пайплайн: найдите аномалии и что-нибудь с ними сделайте до обучения моделей (можно удалить их, а можно использовать в качестве дополнительных признаков - попробуйте разные стратегии). Результат проверьте на кросс-валидации и на лидерборде, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjfDSPh-7-dh"
   },
   "outputs": [],
   "source": [
    "# ваша работа с аномалиями здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWokFc_n8qSR"
   },
   "source": [
    "# **Задание 4 (1 балл)**\n",
    "\n",
    "Сделайте кластеризацию различными способами. Результаты кластеризации используйте для улучшения ML-решений:\n",
    "\n",
    "1) Номера кластеров закодируйте (OHE или target-encoding) и добавьте как новые признаки\n",
    "\n",
    "2) При использовании DBSCAN / HDBSCAN предсказанный шум можно трактовать как найденную аномалию и также добавить ее как новый признак\n",
    "\n",
    "Проведите различные эксперименты. Проверьте как эти подходы влияют на качество прогнозов по кросс-валидации и на лидерборде, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aS2aMVfg9G1h"
   },
   "outputs": [],
   "source": [
    "# ваши эксперименты с кластеризацией здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cLx2cL--7MM"
   },
   "source": [
    "## **Задание 5 (1 балл)**\n",
    "\n",
    "Примените какой-нибудь (один любой) AutoML фреймворк для решения поставленной задачи.\n",
    "\n",
    "Отправьте AutoML-прогноз на kaggle и посмотрите на качество модели. Сделайте текстовые выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rhw85LDV_QJn"
   },
   "outputs": [],
   "source": [
    "# ваш AutoML здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxUr8jaG9JxA"
   },
   "source": [
    "# **Задание 6 (1 балл)**\n",
    "\n",
    "Весь курс мы работали в Google Colab. Но всегда должны быть запасные варианты, где Вы будете обучать модели.\n",
    "\n",
    "Среди вариантов есть:\n",
    "* ваша локальная машина\n",
    "* kaggle notebooks\n",
    "* yandex cloud\n",
    "и другие.\n",
    "\n",
    "Кроме привычного Google Colab выберите из списка выше один любой альтернативный вариант и проведите эксперимент:\n",
    "\n",
    "* Прогоните ваш лучший по качеству по результатам заданий 2-4 ML-пайплайн заново в Google Colab и с помощью библиотек (например, при помощи библиотеки time) замерьте время обучения и отдельно время инференса на тестовых данных\n",
    "\n",
    "* Прогоните этот пайплайн на выбранном альтернативном сервисе/локальной машине и также замерьте время обучения и инференса.\n",
    "\n",
    "Текстом напишите выводы: опишите, какое альтернативное место для обучения моделей Вы использовали? Прикрепите прямо в ноутбук скриншот с экраном кода в альтернативном сервисе/на локальной машине. Также в виде таблицы приведите сравнение времени обучения и инференса в колабе и в альтернативном месте. Сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Os6aMaqS-MjX"
   },
   "outputs": [],
   "source": [
    "# ваши эксперименты здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r-CI3PL9-P45"
   },
   "source": [
    "# **Бонус: за Kaggle и стремление к хорошим скорам (2 балла)**\n",
    "\n",
    "В этом домашнем задании Ваша цель - не просто выполнить шаги выше, но и построить максимально хорошую по качеству модель.\n",
    "\n",
    "**К 10 вы можете получить до двух дополнительных баллов:**\n",
    "\n",
    "* За попадание в топ-20% на private leaderboard — +1 дополнительный балл к оценке\n",
    "* За попадание в топ-5 мест на private leaderboard — + еще один дополнительный балл к оценке (то есть суммарно 2 дополнительных балла)\n",
    "\n",
    "**ВАЖНО!!!**\n",
    "\n",
    "Эти баллы ставятся до мягкого дедлайна по соревнованию. После мягкого дедлайна лидерборд не обновляется, и дополнительные баллы не ставятся.\n",
    "\n",
    "Успехов!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BywMmnkB-s3w"
   },
   "outputs": [],
   "source": [
    "# не забудьте прикрепить скриншоты лидерборда, пожалуйста"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
