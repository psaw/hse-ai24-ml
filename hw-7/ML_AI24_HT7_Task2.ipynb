{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murcha1990/ML_AI24/blob/main/Hometasks/Base/ML_AI24_HT7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Vud7oB5y9q"
      },
      "source": [
        "# **Домашнее задание 7: Fraud Detection Competition**\n",
        "\n",
        "Добро пожаловать на финальное домашнее задание курса! Домашнее задание направлено на систематизацию всех знаний, полученных в процессе учебы.\n",
        "\n",
        "В нём Вы потренируетесь применять навыки построения пайплайнов машинного обучения, приобретенные в курсе от точки разведочного анализа данных до построения и валидации моделей машинного обучения.\n",
        "\n",
        "## **Задача**\n",
        "**Вы будете решать задачу определения фрода:**\n",
        "\n",
        "https://www.kaggle.com/competitions/fraud-detection-24\n",
        "\n",
        "**Вам нужно будет:**\n",
        "- в jupyter notebook провести исследование данных;\n",
        "- в нём же построить модели и оценить их качество;\n",
        "- отправить посылку на Kaggle.\n",
        "\n",
        "Более подробное описание шагов - в ноутбуке ниже.\n",
        "\n",
        "## **Оценивание и баллы**\n",
        "- В EDA и во всей работе будут оцениваться полнота и **выводы**;\n",
        "- При обучении моделей старайтесь обоснованно подходить к их выбору, избегая простого перебора;\n",
        "\n",
        "**Максимальный балл** - 10 (+ бонусы за Kaggle, см. ниже).\n",
        "\n",
        "\n",
        "Мягкий дедлайн (окончание соревнования на Kaggle): **15 марта 23:59**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IdCmv4IoqxHJ"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import scipy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "INPUT_DIR = 'data'\n",
        "\n",
        "train_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'train_transaction.csv'))\n",
        "train_identity = pd.read_csv(os.path.join(INPUT_DIR, 'train_identity.csv'))\n",
        "test_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'test_transaction.csv'))\n",
        "test_identity = pd.read_csv(os.path.join(INPUT_DIR, 'test_identity.csv'))\n",
        "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\n",
        "\n",
        "df_train = train_transaction.merge(train_identity, how='left', on='TransactionID')\n",
        "df_test = test_transaction.merge(test_identity, how='left', on='TransactionID')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES0ZdLnfvPm-"
      },
      "source": [
        "### **Примечания:**\n",
        "\n",
        "**1. Оценка качества и Submission File**\n",
        "- Ответом является число от 0 до 1, метрикой качества - AUC-ROC.\n",
        "- Структура Submission File:\n",
        " - для каждого значения *TransactionID* в тестовых данных вы должны предсказать **вероятность** для столбца *isFraud*.\n",
        " - в файле у вас должно быть две колонки: `TransactionID` и`isFraud`  **для каждой транзакции в датасете**.\n",
        "\n",
        "**2. Объем данных**\n",
        "\n",
        "Поскольку набор данных объемный, могут быть проблемы с переполнением памяти в Collab. Для решения проблемы можете использовать функцию из [этого ноутбука](https://colab.research.google.com/drive/18u75eyFGEoyeWJ_MbsLkcPa6gv2tNI8G#scrollTo=V2L1Nl5CTMMl), разобравшись, что она делает с данными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWNI5i4S7VzN"
      },
      "source": [
        "# **Задание 2 (3 балла)**\n",
        "\n",
        "Обучите несколько ML-моделей для решения поставленной задачи.\n",
        "Оцените их качество двумя способами:\n",
        "\n",
        "1) на кросс-валидации\n",
        "\n",
        "2) на лидерборде\n",
        "\n",
        "Подберите число фолдов на кросс-валидации так, чтобы метрики, которые вы видите, были максимально близки на кросс-валидации и на лидерборде.\n",
        "\n",
        "По результатам экспериментов постройте таблицу:\n",
        "* в каждой строке таблицы - результаты одной модели\n",
        "* по столбцам: качество на кросс-валидации, качество на лидерборде, модель с гиперпараметрами\n",
        "Полученную таблицу вставьте картинкой прямо в ноутбук после ячеек с кодом. Сделайте текстовые выводы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Загрузка данных\n",
        "В предыдущей части было подготовлено 2 дополнительных пары датасетов - с отобранными признаками и с заполненными пропусками.\n",
        "Итого имеем 3 набора данных\n",
        "\n",
        "1. оригинальный с минимальной обработкой\n",
        "2. с отобранными признаками (с пропусками)\n",
        "3. с отобранными признаками и заполненными пропусками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "import catboost as cb\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Вспомогательная функция для экономии памяти**  \n",
        "Взята из ноутбука, который приводили в пример. \n",
        "Моя реализация выше отличается."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reduce_mem_usage(df):\n",
        "    NAlist = [] # Keeps track of columns that have missing values filled in.\n",
        "    for col in tqdm(df.columns):\n",
        "        if df[col].dtype != object:  # Exclude strings\n",
        "\n",
        "            # make variables for Int, max and min\n",
        "            IsInt = False\n",
        "            col_max_value = df[col].max()\n",
        "            col_min_value = df[col].min()\n",
        "\n",
        "            # Integer does not support NA, therefore, NA needs to be filled\n",
        "            if not np.isfinite(df[col]).all():\n",
        "                NAlist.append(col)\n",
        "                df[col] = df[col].fillna(col_min_value - 1)\n",
        "                col_min_value -= 1\n",
        "\n",
        "            # test if column can be converted to an integer\n",
        "            col_as_int = df[col].fillna(0).astype(np.int64)\n",
        "            diff = (df[col] - col_as_int)\n",
        "            diff = diff.sum()\n",
        "            if np.abs(diff) < 0.01:\n",
        "                IsInt = True\n",
        "\n",
        "            # Make Integer/unsigned Integer datatypes\n",
        "            if IsInt:\n",
        "                try:\n",
        "                    if col_min_value >= 0:\n",
        "                        if col_max_value < 255:\n",
        "                            df[col] = df[col].astype(np.uint8)\n",
        "                        elif col_max_value < 65535:\n",
        "                            df[col] = df[col].astype(np.uint16)\n",
        "                        elif col_max_value < 4294967295:\n",
        "                            df[col] = df[col].astype(np.uint32)\n",
        "                        else:\n",
        "                            df[col] = df[col].astype(np.uint64)\n",
        "                    else:\n",
        "                        if col_min_value > np.iinfo(np.int8).min and col_max_value < np.iinfo(np.int8).max:\n",
        "                            df[col] = df[col].astype(np.int8)\n",
        "                        elif col_min_value > np.iinfo(np.int16).min and col_max_value < np.iinfo(np.int16).max:\n",
        "                            df[col] = df[col].astype(np.int16)\n",
        "                        elif col_min_value > np.iinfo(np.int32).min and col_max_value < np.iinfo(np.int32).max:\n",
        "                            df[col] = df[col].astype(np.int32)\n",
        "                        elif col_min_value > np.iinfo(np.int64).min and col_max_value < np.iinfo(np.int64).max:\n",
        "                            df[col] = df[col].astype(np.int64)\n",
        "                except Exception as e:\n",
        "                    print(f'Ошибка конвертации {col}: {e}')\n",
        "\n",
        "            # Make float datatypes 32 bit\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "\n",
        "    return df, NAlist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Исходные данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 434/434 [00:02<00:00, 213.97it/s]\n",
            "100%|██████████| 433/433 [00:00<00:00, 686.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 417559 entries, 0 to 417558\n",
            "Columns: 434 entries, TransactionID to DeviceInfo\n",
            "dtypes: float32(80), int16(30), int8(202), object(31), uint16(22), uint32(3), uint8(66)\n",
            "memory usage: 379.1+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 172981 entries, 0 to 172980\n",
            "Columns: 433 entries, TransactionID to DeviceInfo\n",
            "dtypes: float32(78), int16(40), int8(229), object(31), uint16(24), uint32(3), uint8(28)\n",
            "memory usage: 157.9+ MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INPUT_DIR = 'data'\n",
        "\n",
        "train_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'train_transaction.csv'))\n",
        "train_identity = pd.read_csv(os.path.join(INPUT_DIR, 'train_identity.csv'))\n",
        "test_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'test_transaction.csv'))\n",
        "test_identity = pd.read_csv(os.path.join(INPUT_DIR, 'test_identity.csv'))\n",
        "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\n",
        "\n",
        "df_train = train_transaction.merge(train_identity, how='left', on='TransactionID')\n",
        "del train_transaction, train_identity\n",
        "df_train, df_train_NAlist = reduce_mem_usage(df_train)\n",
        "\n",
        "df_test = test_transaction.merge(test_identity, how='left', on='TransactionID')\n",
        "del test_transaction, test_identity\n",
        "df_test, df_test_NAlist = reduce_mem_usage(df_test)\n",
        "\n",
        "df_train.info(), df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данных есть пропуски"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing data in train: 4.47002%\n",
            "Missing data in test: 4.33051%\n"
          ]
        }
      ],
      "source": [
        "print('Missing data in train: {:.5f}%'.format(df_train.isnull().sum().sum() / (df_train.shape[0] * df_train.shape[1]) * 100))\n",
        "print('Missing data in test: {:.5f}%'.format(df_test.isnull().sum().sum() / (df_test.shape[0] * df_test.shape[1]) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Заполним пропуски в столбцах, где значения выражаются числами - `-1`, а где строками - `'unseen_category'`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing data in train: 0.00000%\n",
            "Missing data in test: 0.00000%\n"
          ]
        }
      ],
      "source": [
        "for col in df_train.columns.drop('isFraud'):\n",
        "    if df_train[col].dtype == 'O':\n",
        "        df_train[col] = df_train[col].fillna('unseen_category')\n",
        "        df_test[col] = df_test[col].fillna('unseen_category')\n",
        "    else:\n",
        "        df_train[col] = df_train[col].fillna(-1)\n",
        "        df_test[col] = df_test[col].fillna(-1)\n",
        "\n",
        "print('Missing data in train: {:.5f}%'.format(df_train.isnull().sum().sum() / (df_train.shape[0] * df_train.shape[1]) * 100))\n",
        "print('Missing data in test: {:.5f}%'.format(df_test.isnull().sum().sum() / (df_test.shape[0] * df_test.shape[1]) * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Закодируем категориальные признаки с помощью [`LabelEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) и сконвертируем их в [`category`](https://pandas.pydata.org/pandas-docs/version/0.23.4/categorical.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 433/433 [00:10<00:00, 40.70it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 417559 entries, 0 to 417558\n",
            "Columns: 434 entries, TransactionID to DeviceInfo\n",
            "dtypes: category(31), float32(80), int16(30), int8(202), uint16(22), uint32(3), uint8(66)\n",
            "memory usage: 293.5 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 172981 entries, 0 to 172980\n",
            "Columns: 433 entries, TransactionID to DeviceInfo\n",
            "dtypes: category(31), float32(78), int16(40), int8(229), uint16(24), uint32(3), uint8(28)\n",
            "memory usage: 122.5 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for col in tqdm(df_train.columns.drop('isFraud')):\n",
        "    if df_train[col].dtype == 'O':\n",
        "        le = LabelEncoder()\n",
        "        le.fit(list(df_train[col]) + list(df_test[col]))\n",
        "        df_train[col] = le.transform(df_train[col])\n",
        "        df_test[col] = le.transform(df_test[col])\n",
        "\n",
        "        df_train[col] = df_train[col].astype('category')\n",
        "        df_test[col] = df_test[col].astype('category')\n",
        "\n",
        "df_train.info(), df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Данные с отобранными признаками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = pd.read_csv('./data/X_train.csv')\n",
        "X_test = pd.read_csv('./data/X_test.csv')\n",
        "\n",
        "X_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "X_test.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Данные с заполненными пропусками"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_processed = pd.read_csv('./data/X_train_processed.csv')\n",
        "X_test_processed = pd.read_csv('./data/X_test_processed.csv')\n",
        "\n",
        "X_train_processed.drop(columns=['Unnamed: 0'], axis=1, inplace=True)\n",
        "X_test_processed.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Целевая переменная"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train=pd.read_csv('./data/y_train.csv')\n",
        "y_train.drop(columns=['Unnamed: 0'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подготовка кросс-валидации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Я уже провел календарный анализ и показал, что признак `TransactionDT` задан в секундах, а обучающая выборка - это данные за 4 месяца с `07.12.2018` до `06.04.2019`.\n",
        "\n",
        "Тогда логично в качестве фолдов для кроссвалидации взять последовательные подвыборки, соответствующие одному месяцу. Это позволит сохранить распределение признаков внутри фолдов.\n",
        "\n",
        "Зададим фолды при помощи индексов, тогда их можно будет применять ко всем трем наборам данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation set 0 length: 134339\n",
            "Validation set 1 length: 89399\n",
            "Validation set 2 length: 92189\n",
            "Validation set 3 length: 101632\n"
          ]
        }
      ],
      "source": [
        "month_length = 3600 * 24 * 30\n",
        "\n",
        "fold0_idx = df_train[df_train['TransactionDT'] < df_train['TransactionDT'].min() + month_length].index\n",
        "fold1_idx = df_train[(df_train['TransactionDT'].min() + month_length <= df_train['TransactionDT']) & (df_train['TransactionDT'] < df_train['TransactionDT'].min() + 2 * month_length)].index\n",
        "fold2_idx = df_train[(df_train['TransactionDT'].min() + 2 * month_length <= df_train['TransactionDT']) & (df_train['TransactionDT'] < df_train['TransactionDT'].min() + 3 * month_length)].index\n",
        "fold3_idx = df_train[df_train['TransactionDT'].min() + 3 * month_length <= df_train['TransactionDT']].index\n",
        "folds_idx = [fold0_idx, fold1_idx, fold2_idx, fold3_idx]\n",
        "\n",
        "print('Validation set 0 length:', len(fold0_idx))\n",
        "print('Validation set 1 length:', len(fold1_idx))\n",
        "print('Validation set 2 length:', len(fold2_idx))\n",
        "print('Validation set 3 length:', len(fold3_idx))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "В данных есть признак-идентификатор объекта - `'TransactionID'`. Заметим, что его значения в обучающей и тестовых выборках не пересекаются:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(df_train['TransactionID']).intersection(set(df_test['TransactionID']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Также не пересекаются значения признака, отвечающего за момент времени - `'TransactionDT'`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(df_train['TransactionDT']).intersection(set(df_test['TransactionDT']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Поэтому удалим эти признаки, чтобы модель их не учитывала.  \n",
        "И удалим `isFraud`  из `df_train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((417559, 431), (172981, 431))"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.drop(['TransactionID', 'TransactionDT', 'isFraud'], axis=1, inplace=True)\n",
        "df_test.drop(['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
        "df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Обучение моделей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "\n",
        "class LightGBMWrapper(BaseEstimator):\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "        self.models = []\n",
        "        self.scores = []\n",
        "        self.models = []\n",
        "        \n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series, folds_idx: list[np.ndarray]):\n",
        "        for i in range(len(folds_idx)):\n",
        "            _X_train = X.drop(folds_idx[i], axis=0)\n",
        "            _y_train = y.drop(folds_idx[i], axis=0)\n",
        "            _X_val = X.iloc[folds_idx[i]]\n",
        "            _y_val = y.iloc[folds_idx[i]]\n",
        "            \n",
        "            lgb_train = lgb.Dataset(_X_train, _y_train)\n",
        "            lgb_eval = lgb.Dataset(_X_val, _y_val, reference=lgb_train)\n",
        "            \n",
        "            _model = lgb.train(self.params, lgb_train, valid_sets=lgb_eval)\n",
        "            self.models.append(_model)\n",
        "            \n",
        "            _y_pred = _model.predict(_X_val)\n",
        "            score_fold = roc_auc_score(_y_val, _y_pred)\n",
        "            self.scores.append(score_fold)\n",
        "            \n",
        "        return np.mean(self.scores)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if not self.models:\n",
        "            raise ValueError(\"Модель не обучена. Сначала выполните fit()\")\n",
        "            \n",
        "        predictions = []\n",
        "        for model in self.models:\n",
        "            predictions.append(model.predict(X))\n",
        "        return np.mean(predictions, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'metric': 'auc',\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 2000,\n",
        "    'seed': 13,\n",
        "    'early_stopping_rounds': 200,\n",
        "    # 'device': \"gpu\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.152000 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 31597\n",
            "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 429\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
            "[LightGBM] [Info] Start training from score -3.178863\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[466]\tvalid_0's auc: 0.904218\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.258247 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 34455\n",
            "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 429\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
            "[LightGBM] [Info] Start training from score -3.348051\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[657]\tvalid_0's auc: 0.924913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.198323 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 34355\n",
            "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 429\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
            "[LightGBM] [Info] Start training from score -3.352958\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[234]\tvalid_0's auc: 0.925934\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.185476 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 34429\n",
            "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 429\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
            "[LightGBM] [Info] Start training from score -3.350619\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[495]\tvalid_0's auc: 0.903993\n"
          ]
        }
      ],
      "source": [
        "lgb1 = LightGBMWrapper(params=params)\n",
        "score1 = lgb1.fit(df_train, y_train, folds_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV AUC-ROC: 0.91476\n"
          ]
        }
      ],
      "source": [
        "print('CV AUC-ROC: {:.5f}'.format(np.mean(score1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 417559 entries, 0 to 417558\n",
            "Columns: 334 entries, TransactionAmt to DeviceInfo\n",
            "dtypes: category(31), float64(257), int64(46)\n",
            "memory usage: 978.5 MB\n"
          ]
        }
      ],
      "source": [
        "X_train_cat = X_train.copy()\n",
        "for col in X_train_cat.columns:\n",
        "    if X_train_cat[col].dtype == 'O':\n",
        "        X_train_cat[col] = X_train_cat[col].astype('category')\n",
        "X_train_cat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108867 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 26295\n",
            "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 332\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
            "[LightGBM] [Info] Start training from score -3.178863\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[607]\tvalid_0's auc: 0.900266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.104840 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 28373\n",
            "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 332\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
            "[LightGBM] [Info] Start training from score -3.348051\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[532]\tvalid_0's auc: 0.922563\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.125571 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 28287\n",
            "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 332\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
            "[LightGBM] [Info] Start training from score -3.352958\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[574]\tvalid_0's auc: 0.924236\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.112625 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 28351\n",
            "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 332\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
            "[LightGBM] [Info] Start training from score -3.350619\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[203]\tvalid_0's auc: 0.903767\n",
            "CV AUC-ROC: 0.91271\n"
          ]
        }
      ],
      "source": [
        "lgb2 = LightGBMWrapper(params=params)\n",
        "score2 = lgb2.fit(X_train_cat, y_train, folds_idx)\n",
        "print('CV AUC-ROC: {:.5f}'.format(np.mean(score2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 417559 entries, 0 to 417558\n",
            "Columns: 498 entries, TransactionAmt to M3_missing\n",
            "dtypes: category(29), float64(128), int64(341)\n",
            "memory usage: 1.5 GB\n"
          ]
        }
      ],
      "source": [
        "X_train_processed_cat = X_train_processed.copy()\n",
        "for col in X_train_processed.columns:\n",
        "    if X_train_processed_cat[col].dtype == 'O':\n",
        "        X_train_processed_cat[col] = X_train_processed_cat[col].astype('category')\n",
        "X_train_processed_cat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 11320, number of negative: 271900\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.144715 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 34441\n",
            "[LightGBM] [Info] Number of data points in the train set: 283220, number of used features: 494\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.039969 -> initscore=-3.178863\n",
            "[LightGBM] [Info] Start training from score -3.178863\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[735]\tvalid_0's auc: 0.901385\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 11144, number of negative: 317016\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.190555 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 36641\n",
            "[LightGBM] [Info] Number of data points in the train set: 328160, number of used features: 495\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033959 -> initscore=-3.348051\n",
            "[LightGBM] [Info] Start training from score -3.348051\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[432]\tvalid_0's auc: 0.921975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 10997, number of negative: 314373\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.192733 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 36498\n",
            "[LightGBM] [Info] Number of data points in the train set: 325370, number of used features: 494\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033798 -> initscore=-3.352958\n",
            "[LightGBM] [Info] Start training from score -3.352958\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[313]\tvalid_0's auc: 0.921587\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yukonoff/code/hse_ai_24/hse-ai24-ml/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
            "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
            "[LightGBM] [Info] Number of positive: 10702, number of negative: 305225\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.191845 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 36641\n",
            "[LightGBM] [Info] Number of data points in the train set: 315927, number of used features: 495\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.033875 -> initscore=-3.350619\n",
            "[LightGBM] [Info] Start training from score -3.350619\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "Early stopping, best iteration is:\n",
            "[400]\tvalid_0's auc: 0.905818\n",
            "CV AUC-ROC: 0.91269\n"
          ]
        }
      ],
      "source": [
        "lgb3 = LightGBMWrapper(params=params)\n",
        "score3 = lgb3.fit(X_train_processed_cat, y_train, folds_idx)\n",
        "print('CV AUC-ROC: {:.5f}'.format(np.mean(score3)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 172981 entries, 0 to 172980\n",
            "Columns: 334 entries, TransactionAmt to DeviceInfo\n",
            "dtypes: category(31), float64(271), int64(32)\n",
            "memory usage: 405.4 MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 172981 entries, 0 to 172980\n",
            "Columns: 498 entries, TransactionAmt to M3_missing\n",
            "dtypes: category(29), float64(128), int64(341)\n",
            "memory usage: 624.1 MB\n"
          ]
        }
      ],
      "source": [
        "# выравнивание типов данных\n",
        "X_test_cat = X_test.copy()\n",
        "for col in X_test_cat.columns:\n",
        "    if X_test_cat[col].dtype == 'O':\n",
        "        X_test_cat[col] = X_test_cat[col].astype('category')\n",
        "X_test_cat.info()\n",
        "\n",
        "X_test_processed_cat = X_test_processed.copy()\n",
        "for col in X_train_processed.columns:\n",
        "    if X_test_processed_cat[col].dtype == 'O':\n",
        "        X_test_processed_cat[col] = X_test_processed_cat[col].astype('category')\n",
        "X_test_processed_cat.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Предсказания сделаны для всех трех моделей:\n",
            "Модель 1 (базовая): (172981,)\n",
            "Модель 2 (категориальные признаки): (172981,)\n",
            "Модель 3 (обработанные категориальные признаки): (172981,)\n",
            "Модель 4 (усреднение 1, 2 и 3): (172981,)\n"
          ]
        }
      ],
      "source": [
        "# Предсказания для всех трех моделей\n",
        "y_pred1 = lgb1.predict(df_test)\n",
        "y_pred2 = lgb2.predict(X_test_cat)\n",
        "y_pred3 = lgb3.predict(X_test_processed_cat)\n",
        "# Усредняем предсказания всех трех моделей\n",
        "y_pred4 = (y_pred1 + y_pred2 + y_pred3) / 3\n",
        "\n",
        "\n",
        "print('Предсказания сделаны для всех трех моделей:')\n",
        "print(f'Модель 1 (базовая): {y_pred1.shape}')\n",
        "print(f'Модель 2 (категориальные признаки): {y_pred2.shape}') \n",
        "print(f'Модель 3 (обработанные категориальные признаки): {y_pred3.shape}')\n",
        "print(f'Модель 4 (усреднение 1, 2 и 3): {y_pred4.shape}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TransactionID</th>\n",
              "      <th>isFraud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3404559</td>\n",
              "      <td>0.001841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3404560</td>\n",
              "      <td>0.060725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3404561</td>\n",
              "      <td>0.016253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3404562</td>\n",
              "      <td>0.006289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3404563</td>\n",
              "      <td>0.445382</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TransactionID   isFraud\n",
              "0        3404559  0.001841\n",
              "1        3404560  0.060725\n",
              "2        3404561  0.016253\n",
              "3        3404562  0.006289\n",
              "4        3404563  0.445382"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sub1 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred1})\n",
        "sub2 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred2})\n",
        "sub3 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred3})\n",
        "sub4 = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': y_pred4})\n",
        "\n",
        "sub4.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "sub1.to_csv('data/submission_lgbm1.csv', index=False) # Score: 0.91599\n",
        "sub2.to_csv('data/submission_lgbm2.csv', index=False) # Score: 0.91674\n",
        "sub3.to_csv('data/submission_lgbm3.csv', index=False) # Score: 0.91699\n",
        "sub4.to_csv('data/submission_lgbm4.csv', index=False) # Score: 0.92049"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Отправка файла на соревнование\n",
        "# !kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm1.csv -m \"Task2: lgbm1\"\n",
        "# !kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm2.csv -m \"Task2: lgbm2\"\n",
        "# !kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm3.csv -m \"Task2: lgbm3\"\n",
        "# !kaggle competitions submit -c fraud-detection-24 -f data/submission_lgbm4.csv -m \"Task2: lgbm4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['models/model_lgb3.joblib']"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Сохраняем все модели.\n",
        "# В LightGBM есть встроенная функция сохранения модели, но у нас самодельная кросс-валидация и 4 модели внутри.\n",
        "# Поэтому сохраняем вручную.\n",
        "import joblib\n",
        "\n",
        "joblib.dump(lgb1, 'models/model_lgb1.joblib')\n",
        "joblib.dump(lgb2, 'models/model_lgb2.joblib')\n",
        "joblib.dump(lgb3, 'models/model_lgb3.joblib')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Результаты и выводы\n",
        "\n",
        "**Подход к построению моделей**\n",
        "1. Были обучены 3 базовые модели LightGBM на разных наборах данных:\n",
        "   - `lgb1` - на исходных данных с базовой предобработкой\n",
        "   - `lgb2` - на данных с отобранными признаками\n",
        "   - `lgb3` - на данных с заполненными пропусками и дополнительной обработкой\n",
        "2. Использована кастомная реализация кросс-валидации:\n",
        "   - 4 фолда, разделенные по временным периодам (по месяцам)\n",
        "   - Это позволило сохранить временную структуру данных\n",
        "   - Каждая модель обучалась отдельно на каждом фолде\n",
        "  \n",
        "Параметры всех моделей\n",
        "```python\n",
        "params = {\n",
        "    'objective': 'binary',\n",
        "    'boosting_type': 'gbdt',\n",
        "    'metric': 'auc',\n",
        "    'n_jobs': -1,\n",
        "    'n_estimators': 2000,\n",
        "    'seed': 13,\n",
        "    'early_stopping_rounds': 200\n",
        "}\n",
        "```\n",
        "**Результаты**\n",
        "| Модель                              | AUC-ROC |  Kaggle |\n",
        "|-------------------------------------|---------|---------|\n",
        "| `lbg1` (базовая)                    | 0.91476 | 0.91599 |\n",
        "| `lgb2` (с отобранными признаками)   | 0.91271 | 0.91674 |\n",
        "| `lgb3` (с обработанными признаками) | 0.91269 | 0.91699 |\n",
        "| Ансамбль (среднее трёх моделей)     |       - | 0.92049 |\n",
        "\n",
        "AUC-ROC ансамбля не указан, т.к. внутри моделей скрыта кастомная кроссвалидация и эти значения AUC-ROC - это уже усредненные AUC-ROC на фолдах.\n",
        "\n",
        "**Выводы**\n",
        "\n",
        "1. **Стабильность**:  \n",
        "        Все три модели показали близкие результаты как на кросс-валидации (CV), так и на тестовой выборке (Kaggle), что говорит о стабильности подхода.\n",
        "2. **Эффективность ансамблирования**:  \n",
        "        Усреднение предсказаний дало значительное улучшение результата (0.92049), что превосходит каждую индивидуальную модель на 0.4%-0.6%\n",
        "3. **Соответствие CV и лидерборда**:  \n",
        "        Результаты на CV хорошо коррелируют с результатами на Kaggle, что подтверждает корректность выбранной схемы валидации.\n",
        "4. **Влияние предобработки**:  \n",
        "        Интересно что более сложная предобработка данных (модели 2 и 3) не дала существенного преимущества на CV, но показала лучшие результаты на тестовой выборке. \n",
        "\n",
        "> Лучшим решением оказался ансамбль всех трёх моделей, что подчеркивает важность разнообразия подходов к обработке данных и построению моделей."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYedT0TJ79RC"
      },
      "source": [
        "# **Задание 3 (2 балла)**\n",
        "\n",
        "Попробуйте подойти к задаче как к поиску аномалий.\n",
        "\n",
        "1) Поищите аномалии (фрод) различными рассмотренными в курсе методами и сделайте прогноз на тестовых данных.\n",
        "\n",
        "Результатом также будет таблица:\n",
        "* по строкам - методы поиска аномалий\n",
        "* по столбцам - качество вашего решения на leaderboard\n",
        "\n",
        "2) Попробуйте встроить поиск аномалий и их удаление в ML-пайплайн: найдите аномалии и что-нибудь с ними сделайте до обучения моделей (можно удалить их, а можно использовать в качестве дополнительных признаков - попробуйте разные стратегии). Результат проверьте на кросс-валидации и на лидерборде, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjfDSPh-7-dh"
      },
      "outputs": [],
      "source": [
        "# ваша работа с аномалиями здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWokFc_n8qSR"
      },
      "source": [
        "# **Задание 4 (1 балл)**\n",
        "\n",
        "Сделайте кластеризацию различными способами. Результаты кластеризации используйте для улучшения ML-решений:\n",
        "\n",
        "1) Номера кластеров закодируйте (OHE или target-encoding) и добавьте как новые признаки\n",
        "\n",
        "2) При использовании DBSCAN / HDBSCAN предсказанный шум можно трактовать как найденную аномалию и также добавить ее как новый признак\n",
        "\n",
        "Проведите различные эксперименты. Проверьте как эти подходы влияют на качество прогнозов по кросс-валидации и на лидерборде, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS2aMVfg9G1h"
      },
      "outputs": [],
      "source": [
        "# ваши эксперименты с кластеризацией здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cLx2cL--7MM"
      },
      "source": [
        "## **Задание 5 (1 балл)**\n",
        "\n",
        "Примените какой-нибудь (один любой) AutoML фреймворк для решения поставленной задачи.\n",
        "\n",
        "Отправьте AutoML-прогноз на kaggle и посмотрите на качество модели. Сделайте текстовые выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhw85LDV_QJn"
      },
      "outputs": [],
      "source": [
        "# ваш AutoML здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxUr8jaG9JxA"
      },
      "source": [
        "# **Задание 6 (1 балл)**\n",
        "\n",
        "Весь курс мы работали в Google Colab. Но всегда должны быть запасные варианты, где Вы будете обучать модели.\n",
        "\n",
        "Среди вариантов есть:\n",
        "* ваша локальная машина\n",
        "* kaggle notebooks\n",
        "* yandex cloud\n",
        "и другие.\n",
        "\n",
        "Кроме привычного Google Colab выберите из списка выше один любой альтернативный вариант и проведите эксперимент:\n",
        "\n",
        "* Прогоните ваш лучший по качеству по результатам заданий 2-4 ML-пайплайн заново в Google Colab и с помощью библиотек (например, при помощи библиотеки time) замерьте время обучения и отдельно время инференса на тестовых данных\n",
        "\n",
        "* Прогоните этот пайплайн на выбранном альтернативном сервисе/локальной машине и также замерьте время обучения и инференса.\n",
        "\n",
        "Текстом напишите выводы: опишите, какое альтернативное место для обучения моделей Вы использовали? Прикрепите прямо в ноутбук скриншот с экраном кода в альтернативном сервисе/на локальной машине. Также в виде таблицы приведите сравнение времени обучения и инференса в колабе и в альтернативном месте. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os6aMaqS-MjX"
      },
      "outputs": [],
      "source": [
        "# ваши эксперименты здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-CI3PL9-P45"
      },
      "source": [
        "# **Бонус: за Kaggle и стремление к хорошим скорам (2 балла)**\n",
        "\n",
        "В этом домашнем задании Ваша цель - не просто выполнить шаги выше, но и построить максимально хорошую по качеству модель.\n",
        "\n",
        "**К 10 вы можете получить до двух дополнительных баллов:**\n",
        "\n",
        "* За попадание в топ-20% на private leaderboard — +1 дополнительный балл к оценке\n",
        "* За попадание в топ-5 мест на private leaderboard — + еще один дополнительный балл к оценке (то есть суммарно 2 дополнительных балла)\n",
        "\n",
        "**ВАЖНО!!!**\n",
        "\n",
        "Эти баллы ставятся до мягкого дедлайна по соревнованию. После мягкого дедлайна лидерборд не обновляется, и дополнительные баллы не ставятся.\n",
        "\n",
        "Успехов!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywMmnkB-s3w"
      },
      "outputs": [],
      "source": [
        "# не забудьте прикрепить скриншоты лидерборда, пожалуйста"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
