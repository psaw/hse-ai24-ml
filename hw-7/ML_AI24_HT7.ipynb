{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murcha1990/ML_AI24/blob/main/Hometasks/Base/ML_AI24_HT7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7Vud7oB5y9q"
      },
      "source": [
        "# **Домашнее задание 7: Fraud Detection Competition**\n",
        "\n",
        "Добро пожаловать на финальное домашнее задание курса! Домашнее задание направлено на систематизацию всех знаний, полученных в процессе учебы.\n",
        "\n",
        "В нём Вы потренируетесь применять навыки построения пайплайнов машинного обучения, приобретенные в курсе от точки разведочного анализа данных до построения и валидации моделей машинного обучения.\n",
        "\n",
        "## **Задача**\n",
        "**Вы будете решать задачу определения фрода:**\n",
        "\n",
        "https://www.kaggle.com/competitions/fraud-detection-24\n",
        "\n",
        "**Вам нужно будет:**\n",
        "- в jupyter notebook провести исследование данных;\n",
        "- в нём же построить модели и оценить их качество;\n",
        "- отправить посылку на Kaggle.\n",
        "\n",
        "Более подробное описание шагов - в ноутбуке ниже.\n",
        "\n",
        "## **Оценивание и баллы**\n",
        "- В EDA и во всей работе будут оцениваться полнота и **выводы**;\n",
        "- При обучении моделей старайтесь обоснованно подходить к их выбору, избегая простого перебора;\n",
        "\n",
        "**Максимальный балл** - 10 (+ бонусы за Kaggle, см. ниже).\n",
        "\n",
        "\n",
        "Мягкий дедлайн (окончание соревнования на Kaggle): **15 марта 23:59**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1oMvDTqqU3V"
      },
      "source": [
        "# **Базовое решение и пример формирования файла под submission**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tPZ6DjAqaW-",
        "outputId": "da044f5a-15d1-426f-89fb-077060794d24",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# # Создаем директорию data, если она не существует\n",
        "# !mkdir -p data\n",
        "\n",
        "# # Скачиваем файлы в директорию data\n",
        "# !wget --no-check-certificate 'https://www.dropbox.com/s/5iuef7c9ljj84t6/train_transaction.csv?dl=0' -O data/train_transaction.csv\n",
        "# !wget --no-check-certificate 'https://www.dropbox.com/s/cmy01z5fw7ohlmd/train_identity.csv?dl=0' -O data/train_identity.csv\n",
        "# !wget --no-check-certificate 'https://www.dropbox.com/s/7thqkuxnwsa7njj/test_transaction.csv?dl=0' -O data/test_transaction.csv\n",
        "# !wget --no-check-certificate 'https://www.dropbox.com/s/b40nvbb9e2usd5w/test_identity.csv?dl=0' -O data/test_identity.csv\n",
        "# !wget --no-check-certificate 'https://www.dropbox.com/s/arkyoz0bel8z4d2/sample_submission.csv?dl=0' -O data/sample_submission.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# # Скачиваем файлы с Kaggle\n",
        "# !pip install kaggle -q\n",
        "\n",
        "# # Убедимся, что директория для API ключа Kaggle существует\n",
        "# !mkdir -p ~/.kaggle\n",
        "\n",
        "# # Создаем файл с API ключом Kaggle (замените на свой ключ)\n",
        "# # Примечание: в реальном использовании лучше загрузить ключ из безопасного хранилища\n",
        "# # !echo '{\"username\":\"your_username\",\"key\":\"your_api_key\"}' > ~/.kaggle/kaggle.json\n",
        "# # !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# # Скачиваем файлы соревнования\n",
        "# !kaggle competitions download -c fraud-detection-24 -p data\n",
        "# !unzip -o data/fraud-detection-24.zip -d data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YrOxS8n8q2v1"
      },
      "outputs": [],
      "source": [
        "!pip install catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IdCmv4IoqxHJ"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "INPUT_DIR = 'data'\n",
        "\n",
        "train_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'train_transaction.csv'))\n",
        "train_identity = pd.read_csv(os.path.join(INPUT_DIR, 'train_identity.csv'))\n",
        "test_transaction = pd.read_csv(os.path.join(INPUT_DIR, 'test_transaction.csv'))\n",
        "test_identity = pd.read_csv(os.path.join(INPUT_DIR, 'test_identity.csv'))\n",
        "sample_submission = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\n",
        "\n",
        "df_train = train_transaction.merge(train_identity, how='left', on='TransactionID')\n",
        "\n",
        "df_test = test_transaction.merge(test_identity, how='left', on='TransactionID')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alfrJEFzrTp6",
        "outputId": "b4e8debe-4f72-4608-f706-c5ee872fa5de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((417559, 432), (172981, 431))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.drop(['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
        "df_test.drop(['TransactionID', 'TransactionDT'], axis=1, inplace=True)\n",
        "df_train.shape, df_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B24-pJJDsijB",
        "outputId": "cf80ff41-a810-4675-de5d-6a049300ade1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "431it [00:00, 83030.73it/s]\n"
          ]
        }
      ],
      "source": [
        "object_cols = []\n",
        "for idx, col in tqdm(enumerate(df_train.columns.drop('isFraud'))):\n",
        "    if df_train[col].dtype == 'O':\n",
        "      object_cols.append(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkAxbs_qtC-b",
        "outputId": "34b8bd7f-019d-46db-a236-fb1bab7ca4c5"
      },
      "outputs": [],
      "source": [
        "X_train = df_train.drop('isFraud', axis=1)\n",
        "X_train = X_train.fillna('')\n",
        "y_train = df_train['isFraud'].values\n",
        "\n",
        "# cb = CatBoostClassifier(iterations=3)\n",
        "# cb.fit(X_train, y_train, object_cols, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a0y2SH1yvKy2"
      },
      "outputs": [],
      "source": [
        "# predictions = cb.predict_proba(df_test.fillna(''))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hGl-RlnSv0Vz",
        "outputId": "ddbe85dd-76e6-41b8-b08b-dfed4fad7d0b"
      },
      "outputs": [],
      "source": [
        "# sub = pd.DataFrame({'TransactionID': sample_submission['TransactionID'], 'isFraud': predictions[:, 0]})\n",
        "# sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-NE7v4_v7jb"
      },
      "outputs": [],
      "source": [
        "# Сохранение submission\n",
        "# sub.to_csv('submission_baseline.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Отправка файла на соревнование\n",
        "# !kaggle competitions submit -c fraud-detection-24 -f submission_baseline.csv -m \"Базовая модель CatBoost\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES0ZdLnfvPm-"
      },
      "source": [
        "### **Примечания:**\n",
        "\n",
        "**1. Оценка качества и Submission File**\n",
        "- Ответом является число от 0 до 1, метрикой качества - AUC-ROC.\n",
        "- Структура Submission File:\n",
        " - для каждого значения *TransactionID* в тестовых данных вы должны предсказать **вероятность** для столбца *isFraud*.\n",
        " - в файле у вас должно быть две колонки: `TransactionID` и`isFraud`  **для каждой транзакции в датасете**.\n",
        "\n",
        "**2. Объем данных**\n",
        "\n",
        "Поскольку набор данных объемный, могут быть проблемы с переполнением памяти в Collab. Для решения проблемы можете использовать функцию из [этого ноутбука](https://colab.research.google.com/drive/18u75eyFGEoyeWJ_MbsLkcPa6gv2tNI8G#scrollTo=V2L1Nl5CTMMl), разобравшись, что она делает с данными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h-Grgsp64a_"
      },
      "source": [
        "# **Задание 1 (2 балла)**\n",
        "\n",
        "Проведите EDA (разведочный анализ данных):\n",
        "* проанализируйте признаки, их особенности и связь с целевой переменной\n",
        "* проанализируйте целевую переменную\n",
        "* оцените степень попарной взаимосвязи признаков, а также связи признаков и целевой переменной\n",
        "* по результатам исследований сделайте необходимую обработку данных (удаление дублей, работа с пропусками, с категориальными столбцами (если они есть), работа с аномалиями, другие преобразования признаков)\n",
        "\n",
        "Важно, что EDA всегда сопровождается выводами - не забудьте об этом."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Анализ признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6moN1PRa5wih"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Информация о тренировочном наборе:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 417559 entries, 0 to 417558\n",
            "Columns: 432 entries, isFraud to DeviceInfo\n",
            "dtypes: float64(399), int64(2), object(31)\n",
            "memory usage: 1.3+ GB\n"
          ]
        }
      ],
      "source": [
        "# ваш EDA здесь\n",
        "print(\"\\nИнформация о тренировочном наборе:\")\n",
        "df_train.info(verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#вывод\n",
        "- В обучающей выборке 432 признака, включая целевую `isFraud`.\n",
        "- dtypes: float64(399), int64(2), object(31)\n",
        "- датасет занимает 1.3ГБ памяти, что много. Возможно типы данных неэффективно выбораны."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Оптимизируем типы данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def reduce_mem_usage(df):\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Использование памяти до оптимизации: {:.2f} MB'.format(start_mem))\n",
        "    for col in tqdm(df.columns):\n",
        "        if df[col].dtype not in ['object', 'category']: \n",
        "\n",
        "            is_NAN_or_INF = np.isfinite(df[col]).any() or df[col].isna().any()\n",
        "\n",
        "            if np.all(np.abs(df[col].dropna() - df[col].dropna().round()) < 1e-15):\n",
        "                rounded = df[col].dropna().round()\n",
        "                rmin = rounded.min()\n",
        "                rmax = rounded.max()\n",
        "\n",
        "                if rmin >= 0:\n",
        "                    if rmax < np.iinfo(np.uint8).max:\n",
        "                        dtype_nullable = 'UInt8'\n",
        "                        dtype_regular = np.uint8\n",
        "                    elif rmax < np.iinfo(np.uint16).max:\n",
        "                        dtype_nullable = 'UInt16'\n",
        "                        dtype_regular = np.uint16\n",
        "                    elif rmax < np.iinfo(np.uint32).max:\n",
        "                        dtype_nullable = 'UInt32'\n",
        "                        dtype_regular = np.uint32\n",
        "                    else:\n",
        "                        dtype_nullable = 'UInt64'\n",
        "                        dtype_regular = np.uint64\n",
        "                else:\n",
        "                    if rmin > np.iinfo(np.int8).min and rmax < np.iinfo(np.int8).max:\n",
        "                        dtype_nullable = 'Int8' \n",
        "                        dtype_regular = np.int8\n",
        "                    elif rmin > np.iinfo(np.int16).min and rmax < np.iinfo(np.int16).max:\n",
        "                        dtype_nullable = 'Int16'\n",
        "                        dtype_regular = np.int16\n",
        "                    elif rmin > np.iinfo(np.int32).min and rmax < np.iinfo(np.int32).max:\n",
        "                        dtype_nullable = 'Int32'\n",
        "                        dtype_regular = np.int32\n",
        "                    elif rmin > np.iinfo(np.int64).min and rmax < np.iinfo(np.int64).max:\n",
        "                        dtype_nullable = 'Int64'\n",
        "                        dtype_regular = np.int64\n",
        "                # Применяем выбранный тип данных\n",
        "                try:\n",
        "                    df[col] = df[col].astype(dtype_nullable) if is_NAN_or_INF else rounded.astype(dtype_regular)\n",
        "                except:\n",
        "                    print(f\"Ошибка на {col}: {df[col].dtype} -> {dtype_nullable=}, {dtype_regular=}, {is_NAN_or_INF=}, {rmin=}, {rmax=}\")\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "            else:\n",
        "                df[col] = df[col].astype(np.float32)\n",
        "        else:  # тип object пытаемся преобразовать в category\n",
        "            try:\n",
        "                df[col] = df[col].astype('category')\n",
        "            except:\n",
        "                print(f\"Ошибка на {col}: {df[col].dtype} -> 'category'\")\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Использование памяти после оптимизации: {:.2f} MB'.format(end_mem))\n",
        "    print('Уменьшение памяти на {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Использование памяти до оптимизации: 1376.23 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 432/432 [00:12<00:00, 33.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Использование памяти после оптимизации: 416.20 MB\n",
            "Уменьшение памяти на 69.8%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "df_train = reduce_mem_usage(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Использование памяти до оптимизации: 568.81 MB\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 431/431 [00:05<00:00, 75.73it/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Использование памяти после оптимизации: 174.10 MB\n",
            "Уменьшение памяти на 69.4%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "df_test = reduce_mem_usage(df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#вывод\n",
        "| Занято памяти | До оптимизации | После оптимизации | Уменьшение |\n",
        "|---------------|----------------|-------------------|------------|\n",
        "| df_train      | 1376.23 MB     | 416.2 MB          | 69.8%      |\n",
        "| df_test       |  568.81 MB     | 174.1 MB          | 69.4%      |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Пропуски"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_values = df_train.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "missing_values[missing_values > 0].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWNI5i4S7VzN"
      },
      "source": [
        "# **Задание 2 (3 балла)**\n",
        "\n",
        "Обучите несколько ML-моделей для решения поставленной задачи.\n",
        "Оцените их качество двумя способами:\n",
        "\n",
        "1) на кросс-валидации\n",
        "\n",
        "2) на лидерборде\n",
        "\n",
        "Подберите число фолдов на кросс-валидации так, чтобы метрики, которые вы видите, были максимально близки на кросс-валидации и на лидерборде.\n",
        "\n",
        "По результатам экспериментов постройте таблицу:\n",
        "* в каждой строке таблицы - результаты одной модели\n",
        "* по столбцам: качество на кросс-валидации, качество на лидерборде, модель с гиперпараметрами\n",
        "Полученную таблицу вставьте картинкой прямо в ноутбук после ячеек с кодом. Сделайте текстовые выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yEMdMQv77og"
      },
      "outputs": [],
      "source": [
        "# ваши модели здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYedT0TJ79RC"
      },
      "source": [
        "# **Задание 3 (2 балла)**\n",
        "\n",
        "Попробуйте подойти к задаче как к поиску аномалий.\n",
        "\n",
        "1) Поищите аномалии (фрод) различными рассмотренными в курсе методами и сделайте прогноз на тестовых данных.\n",
        "\n",
        "Результатом также будет таблица:\n",
        "* по строкам - методы поиска аномалий\n",
        "* по столбцам - качество вашего решения на leaderboard\n",
        "\n",
        "2) Попробуйте встроить поиск аномалий и их удаление в ML-пайплайн: найдите аномалии и что-нибудь с ними сделайте до обучения моделей (можно удалить их, а можно использовать в качестве дополнительных признаков - попробуйте разные стратегии). Результат проверьте на кросс-валидации и на лидерборде, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yjfDSPh-7-dh"
      },
      "outputs": [],
      "source": [
        "# ваша работа с аномалиями здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWokFc_n8qSR"
      },
      "source": [
        "# **Задание 4 (1 балл)**\n",
        "\n",
        "Сделайте кластеризацию различными способами. Результаты кластеризации используйте для улучшения ML-решений:\n",
        "\n",
        "1) Номера кластеров закодируйте (OHE или target-encoding) и добавьте как новые признаки\n",
        "\n",
        "2) При использовании DBSCAN / HDBSCAN предсказанный шум можно трактовать как найденную аномалию и также добавить ее как новый признак\n",
        "\n",
        "Проведите различные эксперименты. Проверьте как эти подходы влияют на качество прогнозов по кросс-валидации и на лидерборде, сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aS2aMVfg9G1h"
      },
      "outputs": [],
      "source": [
        "# ваши эксперименты с кластеризацией здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cLx2cL--7MM"
      },
      "source": [
        "## **Задание 5 (1 балл)**\n",
        "\n",
        "Примените какой-нибудь (один любой) AutoML фреймворк для решения поставленной задачи.\n",
        "\n",
        "Отправьте AutoML-прогноз на kaggle и посмотрите на качество модели. Сделайте текстовые выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rhw85LDV_QJn"
      },
      "outputs": [],
      "source": [
        "# ваш AutoML здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxUr8jaG9JxA"
      },
      "source": [
        "# **Задание 6 (1 балл)**\n",
        "\n",
        "Весь курс мы работали в Google Colab. Но всегда должны быть запасные варианты, где Вы будете обучать модели.\n",
        "\n",
        "Среди вариантов есть:\n",
        "* ваша локальная машина\n",
        "* kaggle notebooks\n",
        "* yandex cloud\n",
        "и другие.\n",
        "\n",
        "Кроме привычного Google Colab выберите из списка выше один любой альтернативный вариант и проведите эксперимент:\n",
        "\n",
        "* Прогоните ваш лучший по качеству по результатам заданий 2-4 ML-пайплайн заново в Google Colab и с помощью библиотек (например, при помощи библиотеки time) замерьте время обучения и отдельно время инференса на тестовых данных\n",
        "\n",
        "* Прогоните этот пайплайн на выбранном альтернативном сервисе/локальной машине и также замерьте время обучения и инференса.\n",
        "\n",
        "Текстом напишите выводы: опишите, какое альтернативное место для обучения моделей Вы использовали? Прикрепите прямо в ноутбук скриншот с экраном кода в альтернативном сервисе/на локальной машине. Также в виде таблицы приведите сравнение времени обучения и инференса в колабе и в альтернативном месте. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os6aMaqS-MjX"
      },
      "outputs": [],
      "source": [
        "# ваши эксперименты здесь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-CI3PL9-P45"
      },
      "source": [
        "# **Бонус: за Kaggle и стремление к хорошим скорам (2 балла)**\n",
        "\n",
        "В этом домашнем задании Ваша цель - не просто выполнить шаги выше, но и построить максимально хорошую по качеству модель.\n",
        "\n",
        "**К 10 вы можете получить до двух дополнительных баллов:**\n",
        "\n",
        "* За попадание в топ-20% на private leaderboard — +1 дополнительный балл к оценке\n",
        "* За попадание в топ-5 мест на private leaderboard — + еще один дополнительный балл к оценке (то есть суммарно 2 дополнительных балла)\n",
        "\n",
        "**ВАЖНО!!!**\n",
        "\n",
        "Эти баллы ставятся до мягкого дедлайна по соревнованию. После мягкого дедлайна лидерборд не обновляется, и дополнительные баллы не ставятся.\n",
        "\n",
        "Успехов!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BywMmnkB-s3w"
      },
      "outputs": [],
      "source": [
        "# не забудьте прикрепить скриншоты лидерборда, пожалуйста"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
