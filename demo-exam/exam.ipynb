{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Чтение тестового набора данных из CSV-файла\n",
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LOCATION_ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "PARA_A",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "PARA_B",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TOTAL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "numbers",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Money_Value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Loss",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "History",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9a6e617c-9365-4df7-a7e3-1acf37614882",
       "rows": [
        [
         "0",
         "4",
         "0.28",
         "0.25",
         "0.53",
         "5.0",
         "0.0",
         "0",
         "0"
        ],
        [
         "1",
         "31",
         "0.0",
         "0.0",
         "0.0",
         "5.0",
         "0.03",
         "0",
         "0"
        ],
        [
         "2",
         "4",
         "5.65",
         "67.16",
         "72.81",
         "6.0",
         "27.23",
         "0",
         "0"
        ],
        [
         "3",
         "11",
         "1.27",
         "0.0",
         "1.27",
         "5.0",
         "175.9",
         "0",
         "0"
        ],
        [
         "4",
         "19",
         "1.6",
         "0.0",
         "1.6",
         "5.0",
         "0.06",
         "0",
         "0"
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOCATION_ID</th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>PARA_B</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>Loss</th>\n",
       "      <th>History</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5.65</td>\n",
       "      <td>67.16</td>\n",
       "      <td>72.81</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LOCATION_ID  PARA_A  PARA_B  TOTAL  numbers  Money_Value  Loss  History\n",
       "0           4    0.28    0.25   0.53      5.0         0.00     0        0\n",
       "1          31    0.00    0.00   0.00      5.0         0.03     0        0\n",
       "2           4    5.65   67.16  72.81      6.0        27.23     0        0\n",
       "3          11    1.27    0.00   1.27      5.0       175.90     0        0\n",
       "4          19    1.60    0.00   1.60      5.0         0.06     0        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOCATION_ID     40\n",
       "PARA_A         287\n",
       "PARA_B         262\n",
       "TOTAL          356\n",
       "numbers          5\n",
       "Money_Value    247\n",
       "Loss             3\n",
       "History          7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Новое количество строк в таблице X_train: 541\n"
     ]
    }
   ],
   "source": [
    "# Проверяем, есть ли нечисловые значения в столбце LOCATION_ID\n",
    "numeric_mask = pd.to_numeric(X_train['LOCATION_ID'], errors='coerce').notna()\n",
    "\n",
    "# Фильтруем только строки с числовыми значениями в LOCATION_ID\n",
    "X_train = X_train[numeric_mask]\n",
    "\n",
    "# Удаляем соответствующие строки из y_train\n",
    "y_train = y_train[numeric_mask].reset_index(drop=True)\n",
    "\n",
    "# Сбрасываем индексы в X_train\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "\n",
    "# Выводим новое количество строк в таблице X_train\n",
    "print(f\"Новое количество строк в таблице X_train: {len(X_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропущенных значений в каждом столбце:\n",
      "LOCATION_ID    0\n",
      "PARA_A         0\n",
      "PARA_B         0\n",
      "TOTAL          0\n",
      "numbers        0\n",
      "Money_Value    1\n",
      "Loss           0\n",
      "History        0\n",
      "dtype: int64\n",
      "\n",
      "Количество строк, содержащих пропущенные значения: 1\n"
     ]
    }
   ],
   "source": [
    "# Проверяем наличие пропущенных значений в тренировочных данных\n",
    "missing_values = X_train.isnull().sum()\n",
    "print(\"Количество пропущенных значений в каждом столбце:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Подсчитываем количество строк с пропущенными значениями\n",
    "rows_with_missing = X_train.isnull().any(axis=1).sum()\n",
    "print(f\"\\nКоличество строк, содержащих пропущенные значения: {rows_with_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 541 entries, 0 to 540\n",
      "Data columns (total 8 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   LOCATION_ID  541 non-null    object \n",
      " 1   PARA_A       541 non-null    float64\n",
      " 2   PARA_B       541 non-null    float64\n",
      " 3   TOTAL        541 non-null    float64\n",
      " 4   numbers      541 non-null    float64\n",
      " 5   Money_Value  540 non-null    float64\n",
      " 6   Loss         541 non-null    int64  \n",
      " 7   History      541 non-null    int64  \n",
      "dtypes: float64(5), int64(2), object(1)\n",
      "memory usage: 33.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропущенных значений в столбце Money_Value после замены: 0\n",
      "Среднее значение, использованное для замены: 16.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f2/942c2cl91r9877yf8jj8c15xr94h9h/T/ipykernel_69025/3651075081.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train['Money_Value'].fillna(mean_money_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Заменяем пропущенные значения в столбце Money_Value на среднее значение\n",
    "mean_money_value = X_train['Money_Value'].mean()\n",
    "X_train['Money_Value'].fillna(mean_money_value, inplace=True)\n",
    "\n",
    "# Проверяем, что пропуски были заменены\n",
    "print(f\"Количество пропущенных значений в столбце Money_Value после замены: {X_train['Money_Value'].isnull().sum()}\")\n",
    "print(f\"Среднее значение, использованное для замены: {mean_money_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество пропущенных значений в каждом столбце:\n",
      "LOCATION_ID    0\n",
      "PARA_A         0\n",
      "PARA_B         0\n",
      "TOTAL          0\n",
      "numbers        0\n",
      "Money_Value    0\n",
      "Loss           0\n",
      "History        0\n",
      "dtype: int64\n",
      "\n",
      "Количество строк, содержащих пропущенные значения: 0\n"
     ]
    }
   ],
   "source": [
    "# Проверяем наличие пропущенных значений в тренировочных данных\n",
    "missing_values = X_test.isnull().sum()\n",
    "print(\"Количество пропущенных значений в каждом столбце:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Подсчитываем количество строк с пропущенными значениями\n",
    "rows_with_missing = X_test.isnull().any(axis=1).sum()\n",
    "print(f\"\\nКоличество строк, содержащих пропущенные значения: {rows_with_missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество различных категорий в X_train: 5\n",
      "\n",
      "Категории в X_train: ['A', 'B', 'C', 'D', 'F']\n",
      "Категории в X_test: ['A']\n",
      "\n",
      "Категории совпадают: False\n"
     ]
    }
   ],
   "source": [
    "# Подсчитываем частоту встречаемости каждого значения LOCATION_ID в X_train\n",
    "location_counts = X_train['LOCATION_ID'].value_counts()\n",
    "\n",
    "# Создаем словарь для маппинга значений\n",
    "mapping = {}\n",
    "for location, count in location_counts.items():\n",
    "    # Определяем букву на основе количества\n",
    "    letter_index = (count - 1) // 10  # 0-9 -> 0, 10-19 -> 1, 20-29 -> 2, etc.\n",
    "    letter = chr(65 + letter_index)  # 65 это ASCII код 'A'\n",
    "    mapping[location] = letter\n",
    "\n",
    "# Применяем маппинг к X_train\n",
    "X_train['LOCATION_ID'] = X_train['LOCATION_ID'].map(mapping)\n",
    "\n",
    "# Применяем маппинг к X_test с дефолтным значением 'A' для новых категорий\n",
    "X_test['LOCATION_ID'] = X_test['LOCATION_ID'].map(lambda x: mapping.get(x, 'A'))\n",
    "\n",
    "# Проверяем количество уникальных категорий в X_train\n",
    "n_categories = X_train['LOCATION_ID'].nunique()\n",
    "print(f\"Количество различных категорий в X_train: {n_categories}\")\n",
    "\n",
    "# Проверяем совпадение категорий\n",
    "train_categories = set(X_train['LOCATION_ID'].unique())\n",
    "test_categories = set(X_test['LOCATION_ID'].unique())\n",
    "print(\"\\nКатегории в X_train:\", sorted(train_categories))\n",
    "print(\"Категории в X_test:\", sorted(test_categories))\n",
    "print(\"\\nКатегории совпадают:\", train_categories == test_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Столбцы в y_train: ['Risk']\n",
      "\n",
      "Пары признаков с высокой корреляцией:\n",
      "PARA_B - TOTAL: 0.994\n",
      "\n",
      "Признаки, которые будут удалены:\n",
      "PARA_B (корреляция с целевой: 0.155)\n",
      "\n",
      "Количество удаленных признаков: 1\n"
     ]
    }
   ],
   "source": [
    "# Сначала посмотрим название столбца в y_train\n",
    "print(\"Столбцы в y_train:\", y_train.columns.tolist())\n",
    "\n",
    "# Получаем список числовых признаков (исключая LOCATION_ID)\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "# Вычисляем корреляционную матрицу\n",
    "corr_matrix = X_train[numeric_features].corr()\n",
    "\n",
    "# Находим пары признаков с корреляцией > 0.9 по модулю\n",
    "high_corr_pairs = []\n",
    "for i in range(len(numeric_features)):\n",
    "    for j in range(i + 1, len(numeric_features)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.9:\n",
    "            feature1 = numeric_features[i]\n",
    "            feature2 = numeric_features[j]\n",
    "            high_corr_pairs.append((feature1, feature2))\n",
    "\n",
    "# Вычисляем корреляцию с целевой переменной\n",
    "# Используем первый столбец y_train, так как обычно он и есть целевая переменная\n",
    "target = y_train.iloc[:, 0]\n",
    "target_corr = abs(X_train[numeric_features].corrwith(target))\n",
    "\n",
    "# Определяем, какие признаки нужно удалить\n",
    "features_to_drop = set()\n",
    "for feat1, feat2 in high_corr_pairs:\n",
    "    # Удаляем признак с меньшей корреляцией с целевой переменной\n",
    "    if target_corr[feat1] < target_corr[feat2]:\n",
    "        features_to_drop.add(feat1)\n",
    "    else:\n",
    "        features_to_drop.add(feat2)\n",
    "\n",
    "# Выводим информацию о найденных парах и удаляемых признаках\n",
    "print(\"\\nПары признаков с высокой корреляцией:\")\n",
    "for feat1, feat2 in high_corr_pairs:\n",
    "    print(f\"{feat1} - {feat2}: {corr_matrix.loc[feat1, feat2]:.3f}\")\n",
    "\n",
    "print(\"\\nПризнаки, которые будут удалены:\")\n",
    "for feat in features_to_drop:\n",
    "    print(f\"{feat} (корреляция с целевой: {target_corr[feat]:.3f})\")\n",
    "\n",
    "# Удаляем выбранные признаки из обоих наборов данных\n",
    "X_train = X_train.drop(columns=features_to_drop)\n",
    "X_test = X_test.drop(columns=features_to_drop)\n",
    "\n",
    "print(f\"\\nКоличество удаленных признаков: {len(features_to_drop)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средние значения PARA_A по классам:\n",
      "Класс 0: 0.28\n",
      "Класс 1: 4.16\n",
      "\n",
      "Максимальное среднее значение: 4.16\n"
     ]
    }
   ],
   "source": [
    "# Группируем данные по значению целевой переменной и вычисляем среднее PARA_A\n",
    "means = X_train.groupby(y_train['Risk'])['PARA_A'].mean()\n",
    "\n",
    "print(\"Средние значения PARA_A по классам:\")\n",
    "for class_label, mean_value in means.items():\n",
    "    print(f\"Класс {class_label}: {mean_value:.2f}\")\n",
    "\n",
    "print(f\"\\nМаксимальное среднее значение: {max(means):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Медиана TOTAL для объектов с Money_Value < 10: 1.08\n"
     ]
    }
   ],
   "source": [
    "# Фильтруем данные по условию Money_Value < 10 и вычисляем медиану TOTAL\n",
    "median_total = X_train[X_train['Money_Value'] < 10]['TOTAL'].median()\n",
    "print(f\"Медиана TOTAL для объектов с Money_Value < 10: {median_total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.08"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train['Money_Value'] < 10]['TOTAL'].sort_values().median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464    1.0600\n",
       "224    1.0700\n",
       "14     1.0700\n",
       "241    1.0700\n",
       "507    1.0800\n",
       "445    1.0800\n",
       "165    1.0900\n",
       "307    1.1000\n",
       "77     1.1000\n",
       "498    1.1000\n",
       "287    1.1000\n",
       "283    1.1000\n",
       "119    1.1000\n",
       "424    1.1000\n",
       "72     1.1106\n",
       "22     1.1200\n",
       "329    1.1200\n",
       "56     1.1200\n",
       "482    1.1300\n",
       "136    1.1400\n",
       "Name: TOTAL, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[X_train['Money_Value'] < 10]['TOTAL'].sort_values()[210:230]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все значения Loss равны 0: False\n",
      "\n",
      "Уникальные значения Loss:\n",
      "[0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Фильтруем объекты с Risk = 1 и PARA_A > 0.5\n",
    "filtered_data = X_train[(y_train['Risk'] == 1) & (X_train['PARA_A'] > 0.5)]\n",
    "\n",
    "# Проверяем, все ли значения Loss равны 0\n",
    "all_zeros = (filtered_data['Loss'] == 0).all()\n",
    "\n",
    "print(f\"Все значения Loss равны 0: {all_zeros}\")\n",
    "\n",
    "# Для проверки выведем уникальные значения Loss\n",
    "print(\"\\nУникальные значения Loss:\")\n",
    "print(filtered_data['Loss'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение Risk для локаций типа 'A': 0.7273\n",
      "Среднее значение Risk для остальных локаций: 0.5960\n",
      "\n",
      "Risk для типа 'A' больше, чем для остальных: True\n"
     ]
    }
   ],
   "source": [
    "# Вычисляем среднее значение Risk для локаций типа \"A\"\n",
    "mean_risk_a = y_train[X_train['LOCATION_ID'] == 'A']['Risk'].mean()\n",
    "\n",
    "# Вычисляем среднее значение Risk для всех остальных локаций\n",
    "mean_risk_others = y_train[X_train['LOCATION_ID'] != 'A']['Risk'].mean()\n",
    "\n",
    "print(f\"Среднее значение Risk для локаций типа 'A': {mean_risk_a:.4f}\")\n",
    "print(f\"Среднее значение Risk для остальных локаций: {mean_risk_others:.4f}\")\n",
    "print(f\"\\nRisk для типа 'A' больше, чем для остальных: {mean_risk_a > mean_risk_others}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75%-квантиль значений History: 0\n"
     ]
    }
   ],
   "source": [
    "# Фильтруем данные по условиям Risk = 0 и numbers = 5.0\n",
    "filtered_data = X_train[(y_train['Risk'] == 0) & (X_train['numbers'] == 5.0)]\n",
    "\n",
    "# Вычисляем 75%-квантиль для столбца History с интерполяцией 'higher'\n",
    "quantile_75 = filtered_data['History'].quantile(0.75, interpolation='higher')\n",
    "\n",
    "print(f\"75%-квантиль значений History: {int(quantile_75)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['History'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество признаков после one-hot encoding: 11\n"
     ]
    }
   ],
   "source": [
    "# Применяем one-hot encoding к столбцу LOCATION_ID\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=['LOCATION_ID'])\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=['LOCATION_ID'])\n",
    "\n",
    "# Убеждаемся, что в тестовых данных есть все категории из тренировочных\n",
    "for col in X_train_encoded.columns:\n",
    "    if col not in X_test_encoded.columns:\n",
    "        X_test_encoded[col] = 0\n",
    "\n",
    "# Приводим порядок столбцов в тестовых данных к порядку в тренировочных\n",
    "X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "\n",
    "# Получаем количество признаков после кодировки\n",
    "n_features = X_train_encoded.shape[1]\n",
    "print(f\"Количество признаков после one-hot encoding: {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PARA_A",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TOTAL",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "numbers",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Money_Value",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Loss",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "History",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LOCATION_ID_A",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "LOCATION_ID_B",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "LOCATION_ID_C",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "LOCATION_ID_D",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "LOCATION_ID_F",
         "rawType": "bool",
         "type": "boolean"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb01cd5e-ead3-4005-931d-615d9437538e",
       "rows": [
        [
         "0",
         "0.28",
         "0.53",
         "5.0",
         "0.0",
         "0",
         "0",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "1",
         "0.0",
         "0.0",
         "5.0",
         "0.03",
         "0",
         "0",
         "True",
         "False",
         "False",
         "False",
         "False"
        ],
        [
         "2",
         "5.65",
         "72.81",
         "6.0",
         "27.23",
         "0",
         "0",
         "False",
         "False",
         "True",
         "False",
         "False"
        ],
        [
         "3",
         "1.27",
         "1.27",
         "5.0",
         "175.9",
         "0",
         "0",
         "False",
         "True",
         "False",
         "False",
         "False"
        ],
        [
         "4",
         "1.6",
         "1.6",
         "5.0",
         "0.06",
         "0",
         "0",
         "False",
         "False",
         "False",
         "False",
         "True"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARA_A</th>\n",
       "      <th>TOTAL</th>\n",
       "      <th>numbers</th>\n",
       "      <th>Money_Value</th>\n",
       "      <th>Loss</th>\n",
       "      <th>History</th>\n",
       "      <th>LOCATION_ID_A</th>\n",
       "      <th>LOCATION_ID_B</th>\n",
       "      <th>LOCATION_ID_C</th>\n",
       "      <th>LOCATION_ID_D</th>\n",
       "      <th>LOCATION_ID_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.53</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.65</td>\n",
       "      <td>72.81</td>\n",
       "      <td>6.0</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.27</td>\n",
       "      <td>1.27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PARA_A  TOTAL  numbers  Money_Value  Loss  History  LOCATION_ID_A  \\\n",
       "0    0.28   0.53      5.0         0.00     0        0          False   \n",
       "1    0.00   0.00      5.0         0.03     0        0           True   \n",
       "2    5.65  72.81      6.0        27.23     0        0          False   \n",
       "3    1.27   1.27      5.0       175.90     0        0          False   \n",
       "4    1.60   1.60      5.0         0.06     0        0          False   \n",
       "\n",
       "   LOCATION_ID_B  LOCATION_ID_C  LOCATION_ID_D  LOCATION_ID_F  \n",
       "0          False           True          False          False  \n",
       "1          False          False          False          False  \n",
       "2          False           True          False          False  \n",
       "3           True          False          False          False  \n",
       "4          False          False          False           True  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Среднее значение accuracy на кросс-валидации: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Создаем модель с параметрами по умолчанию\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    # weights='uniform',\n",
    "    # algorithm='auto',\n",
    "    # leaf_size=30,\n",
    "    # p=2,\n",
    "    # metric='minkowski',\n",
    "    # metric_params=None, \n",
    "    # n_jobs=None\n",
    ")\n",
    "\n",
    "# Проводим кросс-валидацию на тренировочных данных\n",
    "scores = cross_val_score(knn, X_train_encoded, y_train['Risk'], cv=3)\n",
    "\n",
    "# Вычисляем среднее значение accuracy\n",
    "mean_accuracy = scores.mean()\n",
    "\n",
    "print(f\"Среднее значение accuracy на кросс-валидации: {mean_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 19 candidates, totalling 57 fits\n",
      "Оптимальное количество соседей: 5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Создаем базовую модель\n",
    "knn = KNeighborsClassifier(\n",
    "    # weights='uniform',\n",
    "    # algorithm='auto',\n",
    "    # leaf_size=30,\n",
    "    # p=2,\n",
    "    # metric='minkowski'\n",
    ")\n",
    "\n",
    "# Задаем сетку параметров для поиска\n",
    "param_grid = {\n",
    "    'n_neighbors': range(2, 21)  # от 2 до 20 включительно\n",
    "}\n",
    "\n",
    "# Создаем объект GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    knn,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Выполняем поиск по сетке\n",
    "grid_search.fit(X_train_encoded, y_train['Risk'])\n",
    "\n",
    "# Получаем лучшее значение n_neighbors\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Оптимальное количество соседей: {best_n_neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оптимальное количество соседей: 6\n"
     ]
    }
   ],
   "source": [
    "# 1. Находим два признака с наибольшей корреляцией с таргетом\n",
    "numeric_features = X_train_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "target_correlations = abs(X_train_encoded[numeric_features].corrwith(y_train['Risk']))\n",
    "top_2_features = target_correlations.nlargest(2).index.tolist()\n",
    "\n",
    "# 2. Создаем новый признак 'mult' в обоих наборах данных\n",
    "X_train_encoded['mult'] = X_train_encoded[top_2_features[0]] * X_train_encoded[top_2_features[1]]\n",
    "X_test_encoded['mult'] = X_test_encoded[top_2_features[0]] * X_test_encoded[top_2_features[1]]\n",
    "\n",
    "# 3. Создаем и настраиваем GridSearchCV\n",
    "knn = KNeighborsClassifier(\n",
    "    weights='uniform',\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    metric='minkowski'\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': range(2, 21)  # от 2 до 20 включительно\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    knn,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "# 4. Выполняем поиск по сетке\n",
    "grid_search.fit(X_train_encoded, y_train['Risk'])\n",
    "\n",
    "# 5. Получаем лучшее значение n_neighbors\n",
    "best_n_neighbors = grid_search.best_params_['n_neighbors']\n",
    "print(f\"Оптимальное количество соседей: {best_n_neighbors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy на тренировочном наборе: 0.9908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "\n",
    "# 1. Подготовка данных\n",
    "# One-hot кодирование\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=['LOCATION_ID'])\n",
    "X_test_encoded = pd.get_dummies(X_test, columns=['LOCATION_ID'])\n",
    "\n",
    "# Убеждаемся, что в тестовых данных есть все категории из тренировочных\n",
    "for col in X_train_encoded.columns:\n",
    "    if col not in X_test_encoded.columns:\n",
    "        X_test_encoded[col] = 0\n",
    "X_test_encoded = X_test_encoded[X_train_encoded.columns]\n",
    "\n",
    "# 2. Создание новых признаков\n",
    "# Отношения\n",
    "X_train_encoded['PARA_A_to_TOTAL'] = X_train_encoded['PARA_A'] / (X_train_encoded['TOTAL'] + 1e-8)\n",
    "X_test_encoded['PARA_A_to_TOTAL'] = X_test_encoded['PARA_A'] / (X_test_encoded['TOTAL'] + 1e-8)\n",
    "\n",
    "# Взаимодействия\n",
    "X_train_encoded['Money_Value_X_History'] = X_train_encoded['Money_Value'] * X_train_encoded['History']\n",
    "X_test_encoded['Money_Value_X_History'] = X_test_encoded['Money_Value'] * X_test_encoded['History']\n",
    "\n",
    "# Квадратичные признаки для числовых переменных\n",
    "numeric_cols = ['PARA_A', 'TOTAL', 'Money_Value']\n",
    "for col in numeric_cols:\n",
    "    X_train_encoded[f'{col}_squared'] = X_train_encoded[col] ** 2\n",
    "    X_test_encoded[f'{col}_squared'] = X_test_encoded[col] ** 2\n",
    "\n",
    "# 3. Масштабирование числовых признаков\n",
    "scaler = StandardScaler()\n",
    "numeric_features = X_train_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "X_train_encoded[numeric_features] = scaler.fit_transform(X_train_encoded[numeric_features])\n",
    "X_test_encoded[numeric_features] = scaler.transform(X_test_encoded[numeric_features])\n",
    "\n",
    "# 4. Обучение модели\n",
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=3,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Обучаем модель\n",
    "model.fit(X_train_encoded, y_train['Risk'])\n",
    "\n",
    "# Получаем предсказания на тренировочном и тестовом наборах\n",
    "train_pred = model.predict(X_train_encoded)\n",
    "test_pred = model.predict(X_test_encoded)\n",
    "\n",
    "# Оцениваем качество на тренировочном наборе\n",
    "train_accuracy = (train_pred == y_train['Risk']).mean()\n",
    "print(f\"Accuracy на тренировочном наборе: {train_accuracy:.4f}\")\n",
    "\n",
    "# Сохраняем предсказания для тестового набора\n",
    "predictions = pd.DataFrame({'predictions': test_pred})\n",
    "predictions.to_csv('predictions.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
