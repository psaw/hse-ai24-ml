{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_X4O8o98hvT"
      },
      "source": [
        "# Домашнее задание\n",
        "\n",
        "В этом домашнем задании вам предлагается попрактиковаться в обучении моделей в Yandex DataSphere!\n",
        "\n",
        "Вы будете решать задачу на части датасета Epsilon — это один из стандартных наборов данных, который часто используется для тестирования алгоритмов машинного обучения. Он был создан для задач регрессии и содержит сгенерированные данные, которые позволяют оценивать производительность моделей.\n",
        "\n",
        "▎Описание датасета Epsilon:\n",
        "\n",
        "• Цель: Задача регрессии, где цель состоит в предсказании целевой переменной на основе набора признаков.\n",
        "\n",
        "• Признаки: Датасет содержит 2000 признаков, из которых 100 являются полезными для предсказания целевой переменной, а остальные 1900 — шумовыми (неинформативными).\n",
        "\n",
        "• Целевая переменная: Целевая переменная представляет собой линейную комбинацию полезных признаков с добавлением случайного шума."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsS2B2ZI9Cyv"
      },
      "source": [
        "## Задание 1\n",
        "\n",
        "Создайте новый проект в DataSphere.\n",
        "Откройте Jupyter Notebook.\n",
        "Запишите в первой ячейке строки ниже и запустите код.\n",
        "При запуске выберите самую дешевую машину с 1 GPU (T4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YNeKj0e_woxV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%pip install catboost -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m3RstkGGwpel"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostRegressor\n",
        "import pandas as pd\n",
        "import timeit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-yjPfVw9aMz"
      },
      "source": [
        "## Задание 2\n",
        "\n",
        "Скачайте данные для задачи из Yandex Object Storage по ссылке.\n",
        "\n",
        "Далее выделите матрицу объект-признак X и вектор с целевой переменной y (это столбец 0 в исходных данных).\n",
        "\n",
        "Сколько строк в датасете?\n",
        "\n",
        "**Ответ:** 25000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WlM7AfYxwtp9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1961</th>\n",
              "      <th>1962</th>\n",
              "      <th>1963</th>\n",
              "      <th>1964</th>\n",
              "      <th>1965</th>\n",
              "      <th>1966</th>\n",
              "      <th>1967</th>\n",
              "      <th>1968</th>\n",
              "      <th>1969</th>\n",
              "      <th>1970</th>\n",
              "      <th>1971</th>\n",
              "      <th>1972</th>\n",
              "      <th>1973</th>\n",
              "      <th>1974</th>\n",
              "      <th>1975</th>\n",
              "      <th>1976</th>\n",
              "      <th>1977</th>\n",
              "      <th>1978</th>\n",
              "      <th>1979</th>\n",
              "      <th>1980</th>\n",
              "      <th>1981</th>\n",
              "      <th>1982</th>\n",
              "      <th>1983</th>\n",
              "      <th>1984</th>\n",
              "      <th>1985</th>\n",
              "      <th>1986</th>\n",
              "      <th>1987</th>\n",
              "      <th>1988</th>\n",
              "      <th>1989</th>\n",
              "      <th>1990</th>\n",
              "      <th>1991</th>\n",
              "      <th>1992</th>\n",
              "      <th>1993</th>\n",
              "      <th>1994</th>\n",
              "      <th>1995</th>\n",
              "      <th>1996</th>\n",
              "      <th>1997</th>\n",
              "      <th>1998</th>\n",
              "      <th>1999</th>\n",
              "      <th>2000</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.005738</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>0.015977</td>\n",
              "      <td>0.001949</td>\n",
              "      <td>0.035965</td>\n",
              "      <td>-0.012589</td>\n",
              "      <td>-0.005272</td>\n",
              "      <td>-0.018107</td>\n",
              "      <td>0.041178</td>\n",
              "      <td>-0.015026</td>\n",
              "      <td>-0.028819</td>\n",
              "      <td>-0.006537</td>\n",
              "      <td>0.033669</td>\n",
              "      <td>-0.034622</td>\n",
              "      <td>0.041462</td>\n",
              "      <td>-0.006984</td>\n",
              "      <td>0.015137</td>\n",
              "      <td>0.040556</td>\n",
              "      <td>-0.003575</td>\n",
              "      <td>-0.026854</td>\n",
              "      <td>-0.000848</td>\n",
              "      <td>-0.018508</td>\n",
              "      <td>0.037773</td>\n",
              "      <td>0.010988</td>\n",
              "      <td>0.001606</td>\n",
              "      <td>0.001236</td>\n",
              "      <td>-0.000411</td>\n",
              "      <td>0.001886</td>\n",
              "      <td>-0.016363</td>\n",
              "      <td>-0.007835</td>\n",
              "      <td>0.013054</td>\n",
              "      <td>-0.041248</td>\n",
              "      <td>-0.013555</td>\n",
              "      <td>0.029254</td>\n",
              "      <td>-0.022851</td>\n",
              "      <td>0.032329</td>\n",
              "      <td>0.015484</td>\n",
              "      <td>-0.024664</td>\n",
              "      <td>0.003483</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004737</td>\n",
              "      <td>-0.013773</td>\n",
              "      <td>0.011465</td>\n",
              "      <td>0.001008</td>\n",
              "      <td>0.022264</td>\n",
              "      <td>0.008917</td>\n",
              "      <td>-0.016302</td>\n",
              "      <td>0.000937</td>\n",
              "      <td>0.013812</td>\n",
              "      <td>0.019966</td>\n",
              "      <td>-0.043475</td>\n",
              "      <td>-0.004776</td>\n",
              "      <td>0.009994</td>\n",
              "      <td>0.013874</td>\n",
              "      <td>0.039987</td>\n",
              "      <td>-0.030642</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>-0.015720</td>\n",
              "      <td>0.008593</td>\n",
              "      <td>0.005424</td>\n",
              "      <td>0.028540</td>\n",
              "      <td>-0.037337</td>\n",
              "      <td>-0.000306</td>\n",
              "      <td>0.033081</td>\n",
              "      <td>0.035953</td>\n",
              "      <td>-0.018372</td>\n",
              "      <td>0.018434</td>\n",
              "      <td>-0.004643</td>\n",
              "      <td>0.006698</td>\n",
              "      <td>0.010878</td>\n",
              "      <td>-0.007748</td>\n",
              "      <td>-0.018985</td>\n",
              "      <td>0.017533</td>\n",
              "      <td>-0.016377</td>\n",
              "      <td>-0.025507</td>\n",
              "      <td>-0.007074</td>\n",
              "      <td>-0.039108</td>\n",
              "      <td>-0.027469</td>\n",
              "      <td>-0.008356</td>\n",
              "      <td>-0.030009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.032287</td>\n",
              "      <td>0.016732</td>\n",
              "      <td>-0.017783</td>\n",
              "      <td>0.020227</td>\n",
              "      <td>-0.007429</td>\n",
              "      <td>0.038325</td>\n",
              "      <td>-0.013316</td>\n",
              "      <td>-0.004563</td>\n",
              "      <td>0.005065</td>\n",
              "      <td>0.027075</td>\n",
              "      <td>-0.004615</td>\n",
              "      <td>0.022719</td>\n",
              "      <td>-0.001174</td>\n",
              "      <td>-0.005253</td>\n",
              "      <td>0.017911</td>\n",
              "      <td>-0.008285</td>\n",
              "      <td>0.023018</td>\n",
              "      <td>-0.005886</td>\n",
              "      <td>-0.021725</td>\n",
              "      <td>0.008088</td>\n",
              "      <td>-0.001925</td>\n",
              "      <td>0.010360</td>\n",
              "      <td>0.008404</td>\n",
              "      <td>0.046580</td>\n",
              "      <td>-0.037502</td>\n",
              "      <td>-0.016718</td>\n",
              "      <td>-0.009010</td>\n",
              "      <td>0.018608</td>\n",
              "      <td>0.004694</td>\n",
              "      <td>0.008248</td>\n",
              "      <td>0.014946</td>\n",
              "      <td>-0.003008</td>\n",
              "      <td>-0.036849</td>\n",
              "      <td>0.026321</td>\n",
              "      <td>0.039021</td>\n",
              "      <td>0.029011</td>\n",
              "      <td>0.053509</td>\n",
              "      <td>0.008748</td>\n",
              "      <td>-0.026753</td>\n",
              "      <td>...</td>\n",
              "      <td>0.021166</td>\n",
              "      <td>0.033842</td>\n",
              "      <td>0.032127</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>-0.004692</td>\n",
              "      <td>0.029451</td>\n",
              "      <td>0.003939</td>\n",
              "      <td>-0.024806</td>\n",
              "      <td>-0.023525</td>\n",
              "      <td>-0.009425</td>\n",
              "      <td>0.011778</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>-0.013626</td>\n",
              "      <td>0.018617</td>\n",
              "      <td>0.002709</td>\n",
              "      <td>0.019048</td>\n",
              "      <td>0.007278</td>\n",
              "      <td>0.020253</td>\n",
              "      <td>-0.043801</td>\n",
              "      <td>0.055158</td>\n",
              "      <td>-0.021189</td>\n",
              "      <td>0.011909</td>\n",
              "      <td>-0.023126</td>\n",
              "      <td>-0.003718</td>\n",
              "      <td>0.002489</td>\n",
              "      <td>0.007376</td>\n",
              "      <td>0.020273</td>\n",
              "      <td>-0.040885</td>\n",
              "      <td>0.019845</td>\n",
              "      <td>-0.025208</td>\n",
              "      <td>-0.023597</td>\n",
              "      <td>-0.035897</td>\n",
              "      <td>-0.021217</td>\n",
              "      <td>0.001084</td>\n",
              "      <td>0.008088</td>\n",
              "      <td>0.032573</td>\n",
              "      <td>0.001252</td>\n",
              "      <td>0.003677</td>\n",
              "      <td>0.012997</td>\n",
              "      <td>0.009525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.026042</td>\n",
              "      <td>0.005822</td>\n",
              "      <td>0.024423</td>\n",
              "      <td>-0.005320</td>\n",
              "      <td>0.010567</td>\n",
              "      <td>0.005121</td>\n",
              "      <td>0.019061</td>\n",
              "      <td>-0.005601</td>\n",
              "      <td>0.023020</td>\n",
              "      <td>0.001421</td>\n",
              "      <td>-0.014876</td>\n",
              "      <td>0.000457</td>\n",
              "      <td>0.018014</td>\n",
              "      <td>-0.026738</td>\n",
              "      <td>0.028460</td>\n",
              "      <td>-0.005551</td>\n",
              "      <td>0.032041</td>\n",
              "      <td>-0.001586</td>\n",
              "      <td>-0.001274</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>-0.010229</td>\n",
              "      <td>-0.000169</td>\n",
              "      <td>0.026797</td>\n",
              "      <td>0.005379</td>\n",
              "      <td>0.013230</td>\n",
              "      <td>-0.026943</td>\n",
              "      <td>0.000167</td>\n",
              "      <td>-0.040692</td>\n",
              "      <td>0.001488</td>\n",
              "      <td>-0.004061</td>\n",
              "      <td>-0.009515</td>\n",
              "      <td>-0.024695</td>\n",
              "      <td>-0.009305</td>\n",
              "      <td>0.022785</td>\n",
              "      <td>-0.046229</td>\n",
              "      <td>-0.001362</td>\n",
              "      <td>0.021154</td>\n",
              "      <td>-0.004119</td>\n",
              "      <td>-0.007879</td>\n",
              "      <td>...</td>\n",
              "      <td>0.019149</td>\n",
              "      <td>-0.038718</td>\n",
              "      <td>-0.007682</td>\n",
              "      <td>-0.010387</td>\n",
              "      <td>-0.002312</td>\n",
              "      <td>-0.035631</td>\n",
              "      <td>-0.001417</td>\n",
              "      <td>0.005136</td>\n",
              "      <td>-0.022054</td>\n",
              "      <td>-0.024243</td>\n",
              "      <td>-0.023056</td>\n",
              "      <td>-0.005739</td>\n",
              "      <td>0.004376</td>\n",
              "      <td>0.026141</td>\n",
              "      <td>0.024937</td>\n",
              "      <td>-0.035690</td>\n",
              "      <td>0.010754</td>\n",
              "      <td>-0.010134</td>\n",
              "      <td>0.020673</td>\n",
              "      <td>-0.004343</td>\n",
              "      <td>-0.013395</td>\n",
              "      <td>-0.025811</td>\n",
              "      <td>-0.008312</td>\n",
              "      <td>0.035563</td>\n",
              "      <td>0.020299</td>\n",
              "      <td>-0.012911</td>\n",
              "      <td>-0.012708</td>\n",
              "      <td>0.013668</td>\n",
              "      <td>0.003074</td>\n",
              "      <td>-0.028061</td>\n",
              "      <td>-0.002573</td>\n",
              "      <td>-0.064170</td>\n",
              "      <td>0.003719</td>\n",
              "      <td>0.000383</td>\n",
              "      <td>-0.022022</td>\n",
              "      <td>-0.021736</td>\n",
              "      <td>-0.030644</td>\n",
              "      <td>-0.017614</td>\n",
              "      <td>0.008090</td>\n",
              "      <td>-0.023110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.008883</td>\n",
              "      <td>0.021915</td>\n",
              "      <td>0.004105</td>\n",
              "      <td>-0.012184</td>\n",
              "      <td>0.037085</td>\n",
              "      <td>-0.026911</td>\n",
              "      <td>-0.001835</td>\n",
              "      <td>0.013376</td>\n",
              "      <td>0.039198</td>\n",
              "      <td>-0.010749</td>\n",
              "      <td>-0.038545</td>\n",
              "      <td>-0.002609</td>\n",
              "      <td>0.034121</td>\n",
              "      <td>-0.023056</td>\n",
              "      <td>0.039868</td>\n",
              "      <td>-0.020030</td>\n",
              "      <td>0.033576</td>\n",
              "      <td>0.035937</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>-0.008194</td>\n",
              "      <td>0.007799</td>\n",
              "      <td>-0.018153</td>\n",
              "      <td>0.038572</td>\n",
              "      <td>0.003459</td>\n",
              "      <td>0.013427</td>\n",
              "      <td>0.009876</td>\n",
              "      <td>-0.009281</td>\n",
              "      <td>-0.009035</td>\n",
              "      <td>-0.004651</td>\n",
              "      <td>0.000801</td>\n",
              "      <td>0.012578</td>\n",
              "      <td>-0.039997</td>\n",
              "      <td>0.002461</td>\n",
              "      <td>0.026828</td>\n",
              "      <td>-0.014464</td>\n",
              "      <td>0.010976</td>\n",
              "      <td>-0.000261</td>\n",
              "      <td>-0.024141</td>\n",
              "      <td>0.006310</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.028574</td>\n",
              "      <td>-0.008188</td>\n",
              "      <td>-0.003977</td>\n",
              "      <td>0.013828</td>\n",
              "      <td>0.018268</td>\n",
              "      <td>-0.007530</td>\n",
              "      <td>-0.014502</td>\n",
              "      <td>0.009532</td>\n",
              "      <td>-0.009569</td>\n",
              "      <td>0.027312</td>\n",
              "      <td>-0.030824</td>\n",
              "      <td>0.010323</td>\n",
              "      <td>0.022540</td>\n",
              "      <td>-0.005601</td>\n",
              "      <td>0.039152</td>\n",
              "      <td>-0.025755</td>\n",
              "      <td>0.020176</td>\n",
              "      <td>-0.015800</td>\n",
              "      <td>0.001929</td>\n",
              "      <td>-0.002211</td>\n",
              "      <td>0.018374</td>\n",
              "      <td>-0.033326</td>\n",
              "      <td>-0.005877</td>\n",
              "      <td>0.034189</td>\n",
              "      <td>0.038494</td>\n",
              "      <td>-0.034589</td>\n",
              "      <td>-0.002887</td>\n",
              "      <td>-0.007752</td>\n",
              "      <td>0.006511</td>\n",
              "      <td>0.016056</td>\n",
              "      <td>-0.007596</td>\n",
              "      <td>-0.017965</td>\n",
              "      <td>0.010094</td>\n",
              "      <td>0.003548</td>\n",
              "      <td>-0.004301</td>\n",
              "      <td>0.001076</td>\n",
              "      <td>-0.037762</td>\n",
              "      <td>-0.036552</td>\n",
              "      <td>-0.000607</td>\n",
              "      <td>-0.028872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.011601</td>\n",
              "      <td>0.023786</td>\n",
              "      <td>-0.027328</td>\n",
              "      <td>-0.032168</td>\n",
              "      <td>-0.015888</td>\n",
              "      <td>-0.004879</td>\n",
              "      <td>0.083705</td>\n",
              "      <td>-0.057912</td>\n",
              "      <td>-0.023810</td>\n",
              "      <td>-0.019682</td>\n",
              "      <td>0.006109</td>\n",
              "      <td>0.001752</td>\n",
              "      <td>-0.025317</td>\n",
              "      <td>0.026342</td>\n",
              "      <td>-0.020087</td>\n",
              "      <td>0.033633</td>\n",
              "      <td>0.017105</td>\n",
              "      <td>-0.007755</td>\n",
              "      <td>-0.018530</td>\n",
              "      <td>0.005137</td>\n",
              "      <td>-0.031172</td>\n",
              "      <td>0.013526</td>\n",
              "      <td>-0.015305</td>\n",
              "      <td>0.011995</td>\n",
              "      <td>0.015383</td>\n",
              "      <td>-0.018211</td>\n",
              "      <td>0.015624</td>\n",
              "      <td>-0.000032</td>\n",
              "      <td>0.040280</td>\n",
              "      <td>0.016254</td>\n",
              "      <td>-0.068284</td>\n",
              "      <td>0.020131</td>\n",
              "      <td>-0.023008</td>\n",
              "      <td>-0.045610</td>\n",
              "      <td>0.022045</td>\n",
              "      <td>-0.019298</td>\n",
              "      <td>0.013363</td>\n",
              "      <td>-0.048987</td>\n",
              "      <td>0.038767</td>\n",
              "      <td>...</td>\n",
              "      <td>0.008275</td>\n",
              "      <td>0.036259</td>\n",
              "      <td>-0.019819</td>\n",
              "      <td>0.022745</td>\n",
              "      <td>-0.002223</td>\n",
              "      <td>-0.006338</td>\n",
              "      <td>-0.009873</td>\n",
              "      <td>0.024213</td>\n",
              "      <td>-0.002828</td>\n",
              "      <td>-0.021336</td>\n",
              "      <td>0.010702</td>\n",
              "      <td>0.001577</td>\n",
              "      <td>0.005220</td>\n",
              "      <td>-0.010850</td>\n",
              "      <td>-0.022982</td>\n",
              "      <td>0.003274</td>\n",
              "      <td>-0.002836</td>\n",
              "      <td>0.011834</td>\n",
              "      <td>-0.016946</td>\n",
              "      <td>0.014952</td>\n",
              "      <td>-0.006768</td>\n",
              "      <td>0.013806</td>\n",
              "      <td>0.018803</td>\n",
              "      <td>-0.003302</td>\n",
              "      <td>-0.022351</td>\n",
              "      <td>0.020366</td>\n",
              "      <td>0.006664</td>\n",
              "      <td>-0.002367</td>\n",
              "      <td>-0.013472</td>\n",
              "      <td>0.006866</td>\n",
              "      <td>0.005518</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.001875</td>\n",
              "      <td>0.001464</td>\n",
              "      <td>0.021134</td>\n",
              "      <td>0.023382</td>\n",
              "      <td>0.021656</td>\n",
              "      <td>-0.000974</td>\n",
              "      <td>-0.008981</td>\n",
              "      <td>0.027860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2001 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0         1         2         3  ...      1997      1998      1999      2000\n",
              "0  1.0 -0.005738  0.007481  0.015977  ... -0.039108 -0.027469 -0.008356 -0.030009\n",
              "1 -1.0 -0.032287  0.016732 -0.017783  ...  0.001252  0.003677  0.012997  0.009525\n",
              "2 -1.0 -0.026042  0.005822  0.024423  ... -0.030644 -0.017614  0.008090 -0.023110\n",
              "3 -1.0 -0.008883  0.021915  0.004105  ... -0.037762 -0.036552 -0.000607 -0.028872\n",
              "4 -1.0 -0.011601  0.023786 -0.027328  ...  0.021656 -0.000974 -0.008981  0.027860\n",
              "\n",
              "[5 rows x 2001 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data = pd.read_csv(\"https://storage.yandexcloud.net/epsilon/epsilon.csv\")\n",
        "Data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 2001)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = Data.drop(columns=['0']), Data['0']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ6sg6VN9n0h"
      },
      "source": [
        "## Задание 3\n",
        "\n",
        "При помощи train_test_split разбейте данные на тренировочную и тестовую часть в пропорции train : test = 3 : 1 и фиксируйте random_state = 42.\n",
        "\n",
        "Сколько строк попало в test?\n",
        "\n",
        "**Ответ:** 6250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yHlorZtqw2zE"
      },
      "outputs": [],
      "source": [
        "# ваш код здесь\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(6250, 2000)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UIr8XFo90x4"
      },
      "source": [
        "## Задание 4\n",
        "\n",
        "Запустите функции train_on_cpu и train_on_gpu из урока на данных из задания и замерьте время выполнения. Во сколько раз быстрее модель обучается на GPU?\n",
        "\n",
        "**Ответ:** 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 0\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "mkdir -p /tmp/catboost_info\n",
        "ls -l /tmp/catboost_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I0tHGIECwjye"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.9957802\ttest: 0.9958478\tbest: 0.9958478 (0)\ttotal: 347ms\tremaining: 34.4s\n",
            "10:\tlearn: 0.9597630\ttest: 0.9614357\tbest: 0.9614357 (10)\ttotal: 2.86s\tremaining: 23.2s\n",
            "20:\tlearn: 0.9326821\ttest: 0.9363627\tbest: 0.9363627 (20)\ttotal: 5.31s\tremaining: 20s\n",
            "30:\tlearn: 0.9100316\ttest: 0.9151370\tbest: 0.9151370 (30)\ttotal: 7.76s\tremaining: 17.3s\n",
            "40:\tlearn: 0.8920378\ttest: 0.8985657\tbest: 0.8985657 (40)\ttotal: 10.2s\tremaining: 14.7s\n",
            "50:\tlearn: 0.8768287\ttest: 0.8849754\tbest: 0.8849754 (50)\ttotal: 12.6s\tremaining: 12.1s\n",
            "60:\tlearn: 0.8628386\ttest: 0.8723240\tbest: 0.8723240 (60)\ttotal: 15s\tremaining: 9.61s\n",
            "70:\tlearn: 0.8501568\ttest: 0.8608860\tbest: 0.8608860 (70)\ttotal: 17.4s\tremaining: 7.12s\n",
            "80:\tlearn: 0.8392860\ttest: 0.8510374\tbest: 0.8510374 (80)\ttotal: 19.8s\tremaining: 4.66s\n",
            "90:\tlearn: 0.8292436\ttest: 0.8421806\tbest: 0.8421806 (90)\ttotal: 22.2s\tremaining: 2.2s\n",
            "99:\tlearn: 0.8206586\ttest: 0.8347525\tbest: 0.8347525 (99)\ttotal: 24.3s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.8347524696\n",
            "bestIteration = 99\n",
            "\n",
            "Time to fit model on CPU: 26 sec\n"
          ]
        }
      ],
      "source": [
        "def train_on_cpu():\n",
        "    model = CatBoostRegressor(\n",
        "    iterations=100,\n",
        "    learning_rate=0.03,\n",
        "    train_dir = '/tmp/catboost_info'\n",
        "  )\n",
        "\n",
        "    model.fit(\n",
        "      X_train, y_train,\n",
        "      eval_set=(X_test, y_test),\n",
        "      verbose=10\n",
        "  );\n",
        "\n",
        "cpu_time = timeit.timeit('train_on_cpu()',\n",
        "                         setup=\"from __main__ import train_on_cpu\",\n",
        "                         number=1)\n",
        "\n",
        "print('Time to fit model on CPU: {} sec'.format(int(cpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ACGfZxEWzcMy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.9952701\ttest: 0.9956003\tbest: 0.9956003 (0)\ttotal: 49ms\tremaining: 4.85s\n",
            "10:\tlearn: 0.9564941\ttest: 0.9581875\tbest: 0.9581875 (10)\ttotal: 355ms\tremaining: 2.88s\n",
            "20:\tlearn: 0.9279700\ttest: 0.9320542\tbest: 0.9320542 (20)\ttotal: 553ms\tremaining: 2.08s\n",
            "30:\tlearn: 0.9051331\ttest: 0.9109861\tbest: 0.9109861 (30)\ttotal: 749ms\tremaining: 1.67s\n",
            "40:\tlearn: 0.8864570\ttest: 0.8946517\tbest: 0.8946517 (40)\ttotal: 947ms\tremaining: 1.36s\n",
            "50:\tlearn: 0.8699146\ttest: 0.8796359\tbest: 0.8796359 (50)\ttotal: 1.14s\tremaining: 1.1s\n",
            "60:\tlearn: 0.8553280\ttest: 0.8667777\tbest: 0.8667777 (60)\ttotal: 1.34s\tremaining: 858ms\n",
            "70:\tlearn: 0.8423965\ttest: 0.8556583\tbest: 0.8556583 (70)\ttotal: 1.54s\tremaining: 629ms\n",
            "80:\tlearn: 0.8311055\ttest: 0.8460624\tbest: 0.8460624 (80)\ttotal: 1.74s\tremaining: 407ms\n",
            "90:\tlearn: 0.8204726\ttest: 0.8365693\tbest: 0.8365693 (90)\ttotal: 1.93s\tremaining: 191ms\n",
            "99:\tlearn: 0.8119672\ttest: 0.8293228\tbest: 0.8293228 (99)\ttotal: 2.11s\tremaining: 0us\n",
            "bestTest = 0.8293227659\n",
            "bestIteration = 99\n",
            "Time to fit model on GPU: 4 sec\n"
          ]
        }
      ],
      "source": [
        "def train_on_gpu():\n",
        "    model = CatBoostRegressor(\n",
        "    iterations=100,\n",
        "    learning_rate=0.03,\n",
        "    task_type='GPU',\n",
        "    train_dir = '/tmp/catboost_info'\n",
        "  )\n",
        "\n",
        "    model.fit(\n",
        "      X_train, y_train,\n",
        "      eval_set=(X_test, y_test),\n",
        "      verbose=10\n",
        "  )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "gpu_time = timeit.timeit('train_on_gpu()',\n",
        "                         setup=\"from __main__ import train_on_gpu\",\n",
        "                         number=1)\n",
        "\n",
        "print('Time to fit model on GPU: {} sec'.format(int(gpu_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6.046850524600179\n"
          ]
        }
      ],
      "source": [
        "print(cpu_time/gpu_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlE5c56b-dMi"
      },
      "source": [
        "## Задание 5\n",
        "\n",
        "Модифицируйте функцию train_on_gpu() так, чтобы она возвращала обученную модель. С помощью обученной на тренировочных данных модели сделайте прогноз на тесте и вычислите значение метрики r2-score.\n",
        "\n",
        "Округлите ответ до сотых. Какое число получилось?\n",
        "\n",
        "**Ответ:** 0.31"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pcztkIc2-puK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 0.9952701\ttest: 0.9956003\tbest: 0.9956003 (0)\ttotal: 44.1ms\tremaining: 4.37s\n",
            "10:\tlearn: 0.9564941\ttest: 0.9581875\tbest: 0.9581875 (10)\ttotal: 345ms\tremaining: 2.79s\n",
            "20:\tlearn: 0.9279700\ttest: 0.9320542\tbest: 0.9320542 (20)\ttotal: 546ms\tremaining: 2.05s\n",
            "30:\tlearn: 0.9051331\ttest: 0.9109861\tbest: 0.9109861 (30)\ttotal: 743ms\tremaining: 1.65s\n",
            "40:\tlearn: 0.8864570\ttest: 0.8946517\tbest: 0.8946517 (40)\ttotal: 941ms\tremaining: 1.35s\n",
            "50:\tlearn: 0.8699146\ttest: 0.8796359\tbest: 0.8796359 (50)\ttotal: 1.14s\tremaining: 1.09s\n",
            "60:\tlearn: 0.8553280\ttest: 0.8667777\tbest: 0.8667777 (60)\ttotal: 1.33s\tremaining: 854ms\n",
            "70:\tlearn: 0.8423965\ttest: 0.8556583\tbest: 0.8556583 (70)\ttotal: 1.53s\tremaining: 627ms\n",
            "80:\tlearn: 0.8311055\ttest: 0.8460624\tbest: 0.8460624 (80)\ttotal: 1.73s\tremaining: 406ms\n",
            "90:\tlearn: 0.8204726\ttest: 0.8365693\tbest: 0.8365693 (90)\ttotal: 1.93s\tremaining: 191ms\n",
            "99:\tlearn: 0.8119672\ttest: 0.8293228\tbest: 0.8293228 (99)\ttotal: 2.1s\tremaining: 0us\n",
            "bestTest = 0.8293227659\n",
            "bestIteration = 99\n",
            "R2-score: 0.31\n"
          ]
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "model = train_on_gpu()\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R2-score: {r2:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRAlLQah-ClE"
      },
      "source": [
        "## Задание 6\n",
        "\n",
        "При помощи GridSearchCV подберите гиперпараметры CatBoost на тренировочных данных:\n",
        "* n_estimators: [10, 100, 200]\n",
        "* max_depth: [4, 6, 8]\n",
        "\n",
        "Примените обученную методом лучшую модель (best_estimator_) на тестовых данных и выведите r2-score. Округлите его до сотых. Чему он равен?\n",
        "\n",
        "ВАЖНО! При подборе гиперпараметров может не хватать памяти, поэтому в этом случае в CatBoost поставьте `gpu_ram_part=0.5` - это будет означать, что вы ограничиваете использование памяти GPU 50-ю процентами (по умолчанию стоит 95%).\n",
        "\n",
        "**Ответ:** 0.42 (но на Степике 0.41)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CkDVMB03z1F7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
            "[CV] END .......................max_depth=4, n_estimators=10; total time=   2.0s\n",
            "[CV] END .......................max_depth=4, n_estimators=10; total time=   1.8s\n",
            "[CV] END .......................max_depth=4, n_estimators=10; total time=   1.8s\n",
            "[CV] END ......................max_depth=4, n_estimators=100; total time=   2.4s\n",
            "[CV] END ......................max_depth=4, n_estimators=100; total time=   2.5s\n",
            "[CV] END ......................max_depth=4, n_estimators=100; total time=   2.4s\n",
            "[CV] END ......................max_depth=4, n_estimators=200; total time=   3.1s\n",
            "[CV] END ......................max_depth=4, n_estimators=200; total time=   3.3s\n",
            "[CV] END ......................max_depth=4, n_estimators=200; total time=   3.1s\n",
            "[CV] END .......................max_depth=6, n_estimators=10; total time=   1.8s\n",
            "[CV] END .......................max_depth=6, n_estimators=10; total time=   1.9s\n",
            "[CV] END .......................max_depth=6, n_estimators=10; total time=   1.7s\n",
            "[CV] END ......................max_depth=6, n_estimators=100; total time=   3.5s\n",
            "[CV] END ......................max_depth=6, n_estimators=100; total time=   3.6s\n",
            "[CV] END ......................max_depth=6, n_estimators=100; total time=   3.4s\n",
            "[CV] END ......................max_depth=6, n_estimators=200; total time=   5.4s\n",
            "[CV] END ......................max_depth=6, n_estimators=200; total time=   5.4s\n",
            "[CV] END ......................max_depth=6, n_estimators=200; total time=   5.2s\n",
            "[CV] END .......................max_depth=8, n_estimators=10; total time=   2.2s\n",
            "[CV] END .......................max_depth=8, n_estimators=10; total time=   2.2s\n",
            "[CV] END .......................max_depth=8, n_estimators=10; total time=   2.1s\n",
            "[CV] END ......................max_depth=8, n_estimators=100; total time=   7.1s\n",
            "[CV] END ......................max_depth=8, n_estimators=100; total time=   7.2s\n",
            "[CV] END ......................max_depth=8, n_estimators=100; total time=   7.0s\n",
            "[CV] END ......................max_depth=8, n_estimators=200; total time=  12.6s\n",
            "[CV] END ......................max_depth=8, n_estimators=200; total time=  12.5s\n",
            "[CV] END ......................max_depth=8, n_estimators=200; total time=  12.4s\n",
            "R2-score: 0.42\n"
          ]
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "params = {\n",
        "    'n_estimators': [10, 100, 200],\n",
        "    'max_depth': [4, 6, 8]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=CatBoostRegressor(\n",
        "        # iterations=100,\n",
        "        learning_rate=0.03,  # если не указать, то R2 будет 0.51\n",
        "        task_type='GPU',\n",
        "        train_dir = '/tmp/catboost_info',\n",
        "        gpu_ram_part=0.85,\n",
        "        verbose=0\n",
        "    ),\n",
        "    param_grid=params,\n",
        "    scoring='r2',\n",
        "    cv=3,\n",
        "    n_jobs=1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f\"R2-score: {r2:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "DataSphere Kernel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
